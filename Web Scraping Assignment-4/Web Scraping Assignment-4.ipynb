{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a27602e",
   "metadata": {},
   "source": [
    "# Web Scraping Assignment-4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e33487",
   "metadata": {},
   "source": [
    "* Name: Rima Das\n",
    "* Batch : Ds2306"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65660ddf",
   "metadata": {},
   "source": [
    "## Questions:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b833c26f",
   "metadata": {},
   "source": [
    "#### 1. Scrape the details of most viewed videos on YouTube from Wikipedia. Url = https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos You need to find following details:\n",
    "\n",
    "* Rank\n",
    "* Name\n",
    "* Artist\n",
    "* Upload date\n",
    "* Views "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8bafd492",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "import pandas as pd\n",
    "import selenium                                  \n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver                   \n",
    "from selenium.webdriver.common.by import By      \n",
    "\n",
    "import warnings                                  \n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import time                                      \n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "\n",
    "#Importing required exceptions which needs to be handled\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "\n",
    "# Let's Install automated chrome browser and connect it to web driver\n",
    "driver = webdriver.Chrome(service=Service())\n",
    "\n",
    "#maximise the window\n",
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2446469",
   "metadata": {},
   "outputs": [],
   "source": [
    "#opening the website page\n",
    "driver.get(\"https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76debbee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 30 30 30 30\n"
     ]
    }
   ],
   "source": [
    "#Extracting Rank\n",
    "rank=[i.text.strip('.') for i in driver.find_elements(By.XPATH,'//tbody/tr/td[1]')[:30]]\n",
    "\n",
    "#Extracting Name\n",
    "name =[i.text.split('[')[0] for i in driver.find_elements(By.XPATH,'//tr/td[2]')[:30]]\n",
    "\n",
    "#Extracting Artist\n",
    "artist = [i.text for i in driver.find_elements(By.XPATH,'//tr/td[3]')[:30]]\n",
    "\n",
    "#extracting views\n",
    "viewsBillions =[i.text for i in driver.find_elements(By.XPATH,'//tr/td[4]')[:30]]\n",
    "\n",
    "#extracting Upload Date\n",
    "uploadDate=[i.text for i in driver.find_elements(By.XPATH,'//tr/td[5]')[:30]]\n",
    "\n",
    "driver.close()\n",
    "\n",
    "print(len(rank),len(name),len(artist),len(viewsBillions),len(uploadDate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43c6a968",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Upload Date</th>\n",
       "      <th>Views In Billions</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rank</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"Baby Shark Dance\"</td>\n",
       "      <td>Pinkfong Baby Shark - children's songs</td>\n",
       "      <td>June 17, 2016</td>\n",
       "      <td>13.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"Despacito\"</td>\n",
       "      <td>Luis Fonsi</td>\n",
       "      <td>January 12, 2017</td>\n",
       "      <td>8.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"Johny Johny Yes Papa\"</td>\n",
       "      <td>LooLoo Kids - nursery rhymes</td>\n",
       "      <td>October 8, 2016</td>\n",
       "      <td>6.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"Bath Song\"</td>\n",
       "      <td>Cocomelon - nursery rhymes</td>\n",
       "      <td>May 2, 2018</td>\n",
       "      <td>6.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>\"Shape of You\"</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>January 30, 2017</td>\n",
       "      <td>6.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>\"See You Again\"</td>\n",
       "      <td>Wiz Khalifa</td>\n",
       "      <td>April 6, 2015</td>\n",
       "      <td>5.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>\"Wheels on the Bus\"</td>\n",
       "      <td>Cocomelon - nursery rhymes</td>\n",
       "      <td>May 24, 2018</td>\n",
       "      <td>5.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>\"Phonics Song with Two Words\"</td>\n",
       "      <td>ChuChu TV - children's songs</td>\n",
       "      <td>March 6, 2014</td>\n",
       "      <td>5.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>\"Uptown Funk\"</td>\n",
       "      <td>Mark Ronson</td>\n",
       "      <td>November 19, 2014</td>\n",
       "      <td>4.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>\"Learning Colors – Colorful Eggs on a Farm\"</td>\n",
       "      <td>Miroshka TV - children's songs</td>\n",
       "      <td>February 27, 2018</td>\n",
       "      <td>4.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>\"Gangnam Style\"</td>\n",
       "      <td>Psy</td>\n",
       "      <td>July 15, 2012</td>\n",
       "      <td>4.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>\"Masha and the Bear – Recipe for Disaster\"</td>\n",
       "      <td>Get Movies - children's songs</td>\n",
       "      <td>January 31, 2012</td>\n",
       "      <td>4.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>\"Dame Tu Cosita\"</td>\n",
       "      <td>El Chombo</td>\n",
       "      <td>April 5, 2018</td>\n",
       "      <td>4.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>\"Axel F\"</td>\n",
       "      <td>Crazy Frog</td>\n",
       "      <td>June 16, 2009</td>\n",
       "      <td>4.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>\"Sugar\"</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>January 14, 2015</td>\n",
       "      <td>3.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>\"Roar\"</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>September 5, 2013</td>\n",
       "      <td>3.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>\"Counting Stars\"</td>\n",
       "      <td>OneRepublic</td>\n",
       "      <td>May 31, 2013</td>\n",
       "      <td>3.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>\"Baa Baa Black Sheep\"</td>\n",
       "      <td>Cocomelon - nursery rhymes</td>\n",
       "      <td>June 25, 2018</td>\n",
       "      <td>3.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>\"Sorry\"</td>\n",
       "      <td>Justin Bieber</td>\n",
       "      <td>October 22, 2015</td>\n",
       "      <td>3.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>\"Waka Waka (This Time for Africa)\"</td>\n",
       "      <td>Shakira</td>\n",
       "      <td>June 4, 2010</td>\n",
       "      <td>3.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>\"Thinking Out Loud\"</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>October 7, 2014</td>\n",
       "      <td>3.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>\"Lakdi Ki Kathi\"</td>\n",
       "      <td>Jingle Toons</td>\n",
       "      <td>June 14, 2018</td>\n",
       "      <td>3.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>\"Dark Horse\"</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>February 20, 2014</td>\n",
       "      <td>3.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>\"Perfect\"</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>November 9, 2017</td>\n",
       "      <td>3.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>\"Faded\"</td>\n",
       "      <td>Alan Walker</td>\n",
       "      <td>December 3, 2015</td>\n",
       "      <td>3.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>\"Let Her Go\"</td>\n",
       "      <td>Passenger</td>\n",
       "      <td>July 25, 2012</td>\n",
       "      <td>3.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>\"Humpty the train on a fruits ride\"</td>\n",
       "      <td>Kiddiestv Hindi - children's songs</td>\n",
       "      <td>January 26, 2018</td>\n",
       "      <td>3.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>\"Girls Like You\"</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>May 31, 2018</td>\n",
       "      <td>3.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>\"Bailando\"</td>\n",
       "      <td>Enrique Iglesias</td>\n",
       "      <td>April 11, 2014</td>\n",
       "      <td>3.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>\"Lean On\"</td>\n",
       "      <td>Major Lazer</td>\n",
       "      <td>March 22, 2015</td>\n",
       "      <td>3.43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Name  \\\n",
       "Rank                                                \n",
       "1                              \"Baby Shark Dance\"   \n",
       "2                                     \"Despacito\"   \n",
       "3                          \"Johny Johny Yes Papa\"   \n",
       "4                                     \"Bath Song\"   \n",
       "5                                  \"Shape of You\"   \n",
       "6                                 \"See You Again\"   \n",
       "8                             \"Wheels on the Bus\"   \n",
       "7                   \"Phonics Song with Two Words\"   \n",
       "9                                   \"Uptown Funk\"   \n",
       "10    \"Learning Colors – Colorful Eggs on a Farm\"   \n",
       "11                                \"Gangnam Style\"   \n",
       "12     \"Masha and the Bear – Recipe for Disaster\"   \n",
       "13                               \"Dame Tu Cosita\"   \n",
       "14                                       \"Axel F\"   \n",
       "15                                        \"Sugar\"   \n",
       "16                                         \"Roar\"   \n",
       "17                               \"Counting Stars\"   \n",
       "18                          \"Baa Baa Black Sheep\"   \n",
       "19                                        \"Sorry\"   \n",
       "20             \"Waka Waka (This Time for Africa)\"   \n",
       "21                            \"Thinking Out Loud\"   \n",
       "22                               \"Lakdi Ki Kathi\"   \n",
       "23                                   \"Dark Horse\"   \n",
       "24                                      \"Perfect\"   \n",
       "25                                        \"Faded\"   \n",
       "26                                   \"Let Her Go\"   \n",
       "27            \"Humpty the train on a fruits ride\"   \n",
       "28                               \"Girls Like You\"   \n",
       "29                                     \"Bailando\"   \n",
       "30                                      \"Lean On\"   \n",
       "\n",
       "                                      Artist        Upload Date  \\\n",
       "Rank                                                              \n",
       "1     Pinkfong Baby Shark - children's songs      June 17, 2016   \n",
       "2                                 Luis Fonsi   January 12, 2017   \n",
       "3               LooLoo Kids - nursery rhymes    October 8, 2016   \n",
       "4                 Cocomelon - nursery rhymes        May 2, 2018   \n",
       "5                                 Ed Sheeran   January 30, 2017   \n",
       "6                                Wiz Khalifa      April 6, 2015   \n",
       "8                 Cocomelon - nursery rhymes       May 24, 2018   \n",
       "7               ChuChu TV - children's songs      March 6, 2014   \n",
       "9                                Mark Ronson  November 19, 2014   \n",
       "10            Miroshka TV - children's songs  February 27, 2018   \n",
       "11                                       Psy      July 15, 2012   \n",
       "12             Get Movies - children's songs   January 31, 2012   \n",
       "13                                 El Chombo      April 5, 2018   \n",
       "14                                Crazy Frog      June 16, 2009   \n",
       "15                                  Maroon 5   January 14, 2015   \n",
       "16                                Katy Perry  September 5, 2013   \n",
       "17                               OneRepublic       May 31, 2013   \n",
       "18                Cocomelon - nursery rhymes      June 25, 2018   \n",
       "19                             Justin Bieber   October 22, 2015   \n",
       "20                                   Shakira       June 4, 2010   \n",
       "21                                Ed Sheeran    October 7, 2014   \n",
       "22                              Jingle Toons      June 14, 2018   \n",
       "23                                Katy Perry  February 20, 2014   \n",
       "24                                Ed Sheeran   November 9, 2017   \n",
       "25                               Alan Walker   December 3, 2015   \n",
       "26                                 Passenger      July 25, 2012   \n",
       "27        Kiddiestv Hindi - children's songs   January 26, 2018   \n",
       "28                                  Maroon 5       May 31, 2018   \n",
       "29                          Enrique Iglesias     April 11, 2014   \n",
       "30                               Major Lazer     March 22, 2015   \n",
       "\n",
       "     Views In Billions  \n",
       "Rank                    \n",
       "1                13.18  \n",
       "2                 8.23  \n",
       "3                 6.76  \n",
       "4                 6.33  \n",
       "5                 6.05  \n",
       "6                 5.98  \n",
       "8                 5.46  \n",
       "7                 5.42  \n",
       "9                 4.99  \n",
       "10                4.94  \n",
       "11                4.86  \n",
       "12                4.55  \n",
       "13                4.41  \n",
       "14                4.00  \n",
       "15                3.91  \n",
       "16                3.84  \n",
       "17                3.84  \n",
       "18                3.73  \n",
       "19                3.69  \n",
       "20                3.68  \n",
       "21                3.63  \n",
       "22                3.63  \n",
       "23                3.56  \n",
       "24                3.51  \n",
       "25                3.49  \n",
       "26                3.48  \n",
       "27                3.51  \n",
       "28                3.45  \n",
       "29                3.43  \n",
       "30                3.43  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Most_viewed_videos_on_YouTube = pd.DataFrame({\n",
    "    \"Rank\":rank,\n",
    "    \"Name\": name,\n",
    "    \"Artist\": artist,\n",
    "    \"Upload Date\": uploadDate,\n",
    "    \"Views In Billions\": viewsBillions\n",
    "})\n",
    "\n",
    "#set rank as index\n",
    "Most_viewed_videos_on_YouTube = Most_viewed_videos_on_YouTube.set_index('Rank')\n",
    "Most_viewed_videos_on_YouTube"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8edab487",
   "metadata": {},
   "source": [
    "#### 2. Scrape the details team India’s international fixtures from bcci.tv. Url = https://www.bcci.tv/. You need to find following details:\n",
    "*  Match title (I.e. 1 ODI)\n",
    "* Series\n",
    "* Place\n",
    "* Date\n",
    "* Time\n",
    "**Note: - From bcci.tv home page you have reach to the international fixture page through code.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2b3ba13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "import pandas as pd\n",
    "import selenium                                  \n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver                   \n",
    "from selenium.webdriver.common.by import By      \n",
    "\n",
    "import warnings                                  \n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import time                                      \n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "\n",
    "#Importing required exceptions which needs to be handled\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException, ElementClickInterceptedException\n",
    "\n",
    "# Let's Install automated chrome browser and connect it to web driver\n",
    "driver = webdriver.Chrome(service=Service())\n",
    "\n",
    "#maximise the window\n",
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5aa3a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#opening the website page\n",
    "driver.get(\"https://www.bcci.tv/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8688dc02",
   "metadata": {},
   "outputs": [],
   "source": [
    "#opening the International Page\n",
    "international = driver.find_element(By.XPATH,'/html/body/nav/div[1]/div[2]/ul[1]/li[2]/a')\n",
    "international.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a5ccaa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38 38 38 38 38\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Match Title</th>\n",
       "      <th>Series</th>\n",
       "      <th>Place</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1st T20I</td>\n",
       "      <td>INDIA TOUR OF IRELAND 2023</td>\n",
       "      <td>The Village, Dublin</td>\n",
       "      <td>18 AUG 2023</td>\n",
       "      <td>7:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2nd T20I</td>\n",
       "      <td>INDIA TOUR OF IRELAND 2023</td>\n",
       "      <td>The Village, Dublin</td>\n",
       "      <td>20 AUG 2023</td>\n",
       "      <td>7:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3rd T20I</td>\n",
       "      <td>INDIA TOUR OF IRELAND 2023</td>\n",
       "      <td>The Village, Dublin</td>\n",
       "      <td>23 AUG 2023</td>\n",
       "      <td>7:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1st ODI</td>\n",
       "      <td>ASIA CUP 2023</td>\n",
       "      <td>Pallekele International Cricket Stadium, Pall...</td>\n",
       "      <td>2 SEP 2023</td>\n",
       "      <td>10:00 AM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2nd ODI</td>\n",
       "      <td>ASIA CUP 2023</td>\n",
       "      <td>Pallekele International Cricket Stadium, Pall...</td>\n",
       "      <td>4 SEP 2023</td>\n",
       "      <td>10:00 AM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1st ODI</td>\n",
       "      <td>AUSTRALIA TOUR OF INDIA 2023-24</td>\n",
       "      <td>Punjab Cricket Association IS Bindra Stadium,...</td>\n",
       "      <td>22 SEP 2023</td>\n",
       "      <td>1:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2nd ODI</td>\n",
       "      <td>AUSTRALIA TOUR OF INDIA 2023-24</td>\n",
       "      <td>Holkar Cricket Stadium, Indore</td>\n",
       "      <td>24 SEP 2023</td>\n",
       "      <td>1:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3rd ODI</td>\n",
       "      <td>AUSTRALIA TOUR OF INDIA 2023-24</td>\n",
       "      <td>Saurashtra Cricket Association Stadium, Rajkot</td>\n",
       "      <td>27 SEP 2023</td>\n",
       "      <td>1:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1st ODI</td>\n",
       "      <td>ICC MENS WORLD CUP 2023</td>\n",
       "      <td>MA Chidambaram Stadium, Chennai</td>\n",
       "      <td>8 OCT 2023</td>\n",
       "      <td>2:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2nd ODI</td>\n",
       "      <td>ICC MENS WORLD CUP 2023</td>\n",
       "      <td>Arun Jaitley Stadium, Delhi</td>\n",
       "      <td>11 OCT 2023</td>\n",
       "      <td>2:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3rd ODI</td>\n",
       "      <td>ICC MENS WORLD CUP 2023</td>\n",
       "      <td>Narendra Modi Stadium, Ahmedabad</td>\n",
       "      <td>14 OCT 2023</td>\n",
       "      <td>2:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4th ODI</td>\n",
       "      <td>ICC MENS WORLD CUP 2023</td>\n",
       "      <td>Maharashtra Cricket Association Stadium, Pune</td>\n",
       "      <td>19 OCT 2023</td>\n",
       "      <td>2:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>5th ODI</td>\n",
       "      <td>ICC MENS WORLD CUP 2023</td>\n",
       "      <td>Himachal Pradesh Cricket Association Stadium,...</td>\n",
       "      <td>22 OCT 2023</td>\n",
       "      <td>2:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>6th ODI</td>\n",
       "      <td>ICC MENS WORLD CUP 2023</td>\n",
       "      <td>Bharat Ratna Shri Atal Bihari Vajpayee Ekana ...</td>\n",
       "      <td>29 OCT 2023</td>\n",
       "      <td>2:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>7th ODI</td>\n",
       "      <td>ICC MENS WORLD CUP 2023</td>\n",
       "      <td>Wankhede Stadium, Mumbai</td>\n",
       "      <td>2 NOV 2023</td>\n",
       "      <td>2:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>8th ODI</td>\n",
       "      <td>ICC MENS WORLD CUP 2023</td>\n",
       "      <td>Eden Gardens, Kolkata</td>\n",
       "      <td>5 NOV 2023</td>\n",
       "      <td>2:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>9th ODI</td>\n",
       "      <td>ICC MENS WORLD CUP 2023</td>\n",
       "      <td>M Chinnaswamy Stadium, Bengaluru</td>\n",
       "      <td>12 NOV 2023</td>\n",
       "      <td>2:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1st T20I</td>\n",
       "      <td>AUSTRALIA TOUR OF INDIA 2023-24</td>\n",
       "      <td>Dr YS Rajasekhara Reddy ACA-VDCA Cricket Stad...</td>\n",
       "      <td>23 NOV 2023</td>\n",
       "      <td>7:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2nd T20I</td>\n",
       "      <td>AUSTRALIA TOUR OF INDIA 2023-24</td>\n",
       "      <td>Greenfield International Stadium, Thiruvanant...</td>\n",
       "      <td>26 NOV 2023</td>\n",
       "      <td>7:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>3rd T20I</td>\n",
       "      <td>AUSTRALIA TOUR OF INDIA 2023-24</td>\n",
       "      <td>Barsapara Cricket Stadium, Guwahati</td>\n",
       "      <td>28 NOV 2023</td>\n",
       "      <td>7:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>4th T20I</td>\n",
       "      <td>AUSTRALIA TOUR OF INDIA 2023-24</td>\n",
       "      <td>Vidarbha Cricket Association Stadium, Nagpur</td>\n",
       "      <td>1 DEC 2023</td>\n",
       "      <td>7:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>5th T20I</td>\n",
       "      <td>AUSTRALIA TOUR OF INDIA 2023-24</td>\n",
       "      <td>Rajiv Gandhi International Stadium, Hyderabad</td>\n",
       "      <td>3 DEC 2023</td>\n",
       "      <td>7:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1st T20I</td>\n",
       "      <td>INDIA TOUR OF SOUTH AFRICA 2023-24</td>\n",
       "      <td>Kingsmead, Durban</td>\n",
       "      <td>10 DEC 2023</td>\n",
       "      <td>9:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2nd T20I</td>\n",
       "      <td>INDIA TOUR OF SOUTH AFRICA 2023-24</td>\n",
       "      <td>St George's Park, Gqeberha</td>\n",
       "      <td>12 DEC 2023</td>\n",
       "      <td>9:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>3rd T20I</td>\n",
       "      <td>INDIA TOUR OF SOUTH AFRICA 2023-24</td>\n",
       "      <td>The Wanderers Stadium, Johannesburg</td>\n",
       "      <td>14 DEC 2023</td>\n",
       "      <td>9:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1st ODI</td>\n",
       "      <td>INDIA TOUR OF SOUTH AFRICA 2023-24</td>\n",
       "      <td>Johannesburg</td>\n",
       "      <td>17 DEC 2023</td>\n",
       "      <td>2:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2nd ODI</td>\n",
       "      <td>INDIA TOUR OF SOUTH AFRICA 2023-24</td>\n",
       "      <td>St George's Park, Gqeberha</td>\n",
       "      <td>19 DEC 2023</td>\n",
       "      <td>2:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>3rd ODI</td>\n",
       "      <td>INDIA TOUR OF SOUTH AFRICA 2023-24</td>\n",
       "      <td>Boland Park, Paarl</td>\n",
       "      <td>21 DEC 2023</td>\n",
       "      <td>2:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1st Test</td>\n",
       "      <td>INDIA TOUR OF SOUTH AFRICA 2023-24</td>\n",
       "      <td>SuperSport Park, Centurion</td>\n",
       "      <td>26 DEC 2023</td>\n",
       "      <td>1:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2nd Test</td>\n",
       "      <td>INDIA TOUR OF SOUTH AFRICA 2023-24</td>\n",
       "      <td>Newlands, Cape Town</td>\n",
       "      <td>3 JAN 2024</td>\n",
       "      <td>1:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1st T20I</td>\n",
       "      <td>AFGHANISTAN TOUR OF INDIA 2023-24</td>\n",
       "      <td>Punjab Cricket Association IS Bindra Stadium,...</td>\n",
       "      <td>11 JAN 2024</td>\n",
       "      <td>7:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2nd T20I</td>\n",
       "      <td>AFGHANISTAN TOUR OF INDIA 2023-24</td>\n",
       "      <td>Holkar Cricket Stadium, Indore</td>\n",
       "      <td>14 JAN 2024</td>\n",
       "      <td>7:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>3rd T20I</td>\n",
       "      <td>AFGHANISTAN TOUR OF INDIA 2023-24</td>\n",
       "      <td>M Chinnaswamy Stadium, Bengaluru</td>\n",
       "      <td>17 JAN 2024</td>\n",
       "      <td>7:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1st Test</td>\n",
       "      <td>ENGLAND TOUR OF INDIA 2023-24</td>\n",
       "      <td>Rajiv Gandhi International Stadium, Hyderabad</td>\n",
       "      <td>25 JAN 2024</td>\n",
       "      <td>9:30 AM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2nd Test</td>\n",
       "      <td>ENGLAND TOUR OF INDIA 2023-24</td>\n",
       "      <td>Dr YS Rajasekhara Reddy ACA-VDCA Cricket Stad...</td>\n",
       "      <td>2 FEB 2024</td>\n",
       "      <td>9:30 AM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>3rd Test</td>\n",
       "      <td>ENGLAND TOUR OF INDIA 2023-24</td>\n",
       "      <td>Saurashtra Cricket Association Stadium, Rajkot</td>\n",
       "      <td>15 FEB 2024</td>\n",
       "      <td>9:30 AM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>4th Test</td>\n",
       "      <td>ENGLAND TOUR OF INDIA 2023-24</td>\n",
       "      <td>JSCA International Stadium Complex, Ranchi</td>\n",
       "      <td>23 FEB 2024</td>\n",
       "      <td>9:30 AM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>5th Test</td>\n",
       "      <td>ENGLAND TOUR OF INDIA 2023-24</td>\n",
       "      <td>Himachal Pradesh Cricket Association Stadium,...</td>\n",
       "      <td>7 MAR 2024</td>\n",
       "      <td>9:30 AM IST</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Match Title                              Series  \\\n",
       "0     1st T20I          INDIA TOUR OF IRELAND 2023   \n",
       "1     2nd T20I          INDIA TOUR OF IRELAND 2023   \n",
       "2     3rd T20I          INDIA TOUR OF IRELAND 2023   \n",
       "3      1st ODI                       ASIA CUP 2023   \n",
       "4      2nd ODI                       ASIA CUP 2023   \n",
       "5      1st ODI     AUSTRALIA TOUR OF INDIA 2023-24   \n",
       "6      2nd ODI     AUSTRALIA TOUR OF INDIA 2023-24   \n",
       "7      3rd ODI     AUSTRALIA TOUR OF INDIA 2023-24   \n",
       "8      1st ODI             ICC MENS WORLD CUP 2023   \n",
       "9      2nd ODI             ICC MENS WORLD CUP 2023   \n",
       "10     3rd ODI             ICC MENS WORLD CUP 2023   \n",
       "11     4th ODI             ICC MENS WORLD CUP 2023   \n",
       "12     5th ODI             ICC MENS WORLD CUP 2023   \n",
       "13     6th ODI             ICC MENS WORLD CUP 2023   \n",
       "14     7th ODI             ICC MENS WORLD CUP 2023   \n",
       "15     8th ODI             ICC MENS WORLD CUP 2023   \n",
       "16     9th ODI             ICC MENS WORLD CUP 2023   \n",
       "17    1st T20I     AUSTRALIA TOUR OF INDIA 2023-24   \n",
       "18    2nd T20I     AUSTRALIA TOUR OF INDIA 2023-24   \n",
       "19    3rd T20I     AUSTRALIA TOUR OF INDIA 2023-24   \n",
       "20    4th T20I     AUSTRALIA TOUR OF INDIA 2023-24   \n",
       "21    5th T20I     AUSTRALIA TOUR OF INDIA 2023-24   \n",
       "22    1st T20I  INDIA TOUR OF SOUTH AFRICA 2023-24   \n",
       "23    2nd T20I  INDIA TOUR OF SOUTH AFRICA 2023-24   \n",
       "24    3rd T20I  INDIA TOUR OF SOUTH AFRICA 2023-24   \n",
       "25     1st ODI  INDIA TOUR OF SOUTH AFRICA 2023-24   \n",
       "26     2nd ODI  INDIA TOUR OF SOUTH AFRICA 2023-24   \n",
       "27     3rd ODI  INDIA TOUR OF SOUTH AFRICA 2023-24   \n",
       "28    1st Test  INDIA TOUR OF SOUTH AFRICA 2023-24   \n",
       "29    2nd Test  INDIA TOUR OF SOUTH AFRICA 2023-24   \n",
       "30    1st T20I   AFGHANISTAN TOUR OF INDIA 2023-24   \n",
       "31    2nd T20I   AFGHANISTAN TOUR OF INDIA 2023-24   \n",
       "32    3rd T20I   AFGHANISTAN TOUR OF INDIA 2023-24   \n",
       "33    1st Test       ENGLAND TOUR OF INDIA 2023-24   \n",
       "34    2nd Test       ENGLAND TOUR OF INDIA 2023-24   \n",
       "35    3rd Test       ENGLAND TOUR OF INDIA 2023-24   \n",
       "36    4th Test       ENGLAND TOUR OF INDIA 2023-24   \n",
       "37    5th Test       ENGLAND TOUR OF INDIA 2023-24   \n",
       "\n",
       "                                                Place         Date  \\\n",
       "0                                 The Village, Dublin  18 AUG 2023   \n",
       "1                                 The Village, Dublin  20 AUG 2023   \n",
       "2                                 The Village, Dublin  23 AUG 2023   \n",
       "3    Pallekele International Cricket Stadium, Pall...   2 SEP 2023   \n",
       "4    Pallekele International Cricket Stadium, Pall...   4 SEP 2023   \n",
       "5    Punjab Cricket Association IS Bindra Stadium,...  22 SEP 2023   \n",
       "6                      Holkar Cricket Stadium, Indore  24 SEP 2023   \n",
       "7      Saurashtra Cricket Association Stadium, Rajkot  27 SEP 2023   \n",
       "8                     MA Chidambaram Stadium, Chennai   8 OCT 2023   \n",
       "9                         Arun Jaitley Stadium, Delhi  11 OCT 2023   \n",
       "10                   Narendra Modi Stadium, Ahmedabad  14 OCT 2023   \n",
       "11      Maharashtra Cricket Association Stadium, Pune  19 OCT 2023   \n",
       "12   Himachal Pradesh Cricket Association Stadium,...  22 OCT 2023   \n",
       "13   Bharat Ratna Shri Atal Bihari Vajpayee Ekana ...  29 OCT 2023   \n",
       "14                           Wankhede Stadium, Mumbai   2 NOV 2023   \n",
       "15                              Eden Gardens, Kolkata   5 NOV 2023   \n",
       "16                   M Chinnaswamy Stadium, Bengaluru  12 NOV 2023   \n",
       "17   Dr YS Rajasekhara Reddy ACA-VDCA Cricket Stad...  23 NOV 2023   \n",
       "18   Greenfield International Stadium, Thiruvanant...  26 NOV 2023   \n",
       "19                Barsapara Cricket Stadium, Guwahati  28 NOV 2023   \n",
       "20       Vidarbha Cricket Association Stadium, Nagpur   1 DEC 2023   \n",
       "21      Rajiv Gandhi International Stadium, Hyderabad   3 DEC 2023   \n",
       "22                                  Kingsmead, Durban  10 DEC 2023   \n",
       "23                         St George's Park, Gqeberha  12 DEC 2023   \n",
       "24                The Wanderers Stadium, Johannesburg  14 DEC 2023   \n",
       "25                                       Johannesburg  17 DEC 2023   \n",
       "26                         St George's Park, Gqeberha  19 DEC 2023   \n",
       "27                                 Boland Park, Paarl  21 DEC 2023   \n",
       "28                         SuperSport Park, Centurion  26 DEC 2023   \n",
       "29                                Newlands, Cape Town   3 JAN 2024   \n",
       "30   Punjab Cricket Association IS Bindra Stadium,...  11 JAN 2024   \n",
       "31                     Holkar Cricket Stadium, Indore  14 JAN 2024   \n",
       "32                   M Chinnaswamy Stadium, Bengaluru  17 JAN 2024   \n",
       "33      Rajiv Gandhi International Stadium, Hyderabad  25 JAN 2024   \n",
       "34   Dr YS Rajasekhara Reddy ACA-VDCA Cricket Stad...   2 FEB 2024   \n",
       "35     Saurashtra Cricket Association Stadium, Rajkot  15 FEB 2024   \n",
       "36         JSCA International Stadium Complex, Ranchi  23 FEB 2024   \n",
       "37   Himachal Pradesh Cricket Association Stadium,...   7 MAR 2024   \n",
       "\n",
       "            Time  \n",
       "0    7:30 PM IST  \n",
       "1    7:30 PM IST  \n",
       "2    7:30 PM IST  \n",
       "3   10:00 AM IST  \n",
       "4   10:00 AM IST  \n",
       "5    1:30 PM IST  \n",
       "6    1:30 PM IST  \n",
       "7    1:30 PM IST  \n",
       "8    2:00 PM IST  \n",
       "9    2:00 PM IST  \n",
       "10   2:00 PM IST  \n",
       "11   2:00 PM IST  \n",
       "12   2:00 PM IST  \n",
       "13   2:00 PM IST  \n",
       "14   2:00 PM IST  \n",
       "15   2:00 PM IST  \n",
       "16   2:00 PM IST  \n",
       "17   7:00 PM IST  \n",
       "18   7:00 PM IST  \n",
       "19   7:00 PM IST  \n",
       "20   7:00 PM IST  \n",
       "21   7:00 PM IST  \n",
       "22   9:30 PM IST  \n",
       "23   9:30 PM IST  \n",
       "24   9:30 PM IST  \n",
       "25   2:00 PM IST  \n",
       "26   2:00 PM IST  \n",
       "27   2:00 PM IST  \n",
       "28   1:30 PM IST  \n",
       "29   1:30 PM IST  \n",
       "30   7:00 PM IST  \n",
       "31   7:00 PM IST  \n",
       "32   7:00 PM IST  \n",
       "33   9:30 AM IST  \n",
       "34   9:30 AM IST  \n",
       "35   9:30 AM IST  \n",
       "36   9:30 AM IST  \n",
       "37   9:30 AM IST  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#accepting cooking\n",
    "try:\n",
    "    cookie=driver.find_element(By.XPATH,'//button[@class=\"cookie__accept btn btn-primary\"]')\n",
    "    cookie.click()\n",
    "except NoSuchElementException:\n",
    "    print('No Exception Occured')\n",
    "\n",
    "# CLicking more button\n",
    "while(True):\n",
    "    try:\n",
    "        more = driver.find_element(By.XPATH,'//button[@class=\"match-btn btn-red d-flex align-items-center justify-content-center mx-auto mt-3\"]')\n",
    "        more.click()\n",
    "    except NoSuchElementException:\n",
    "        break\n",
    "        \n",
    "#Extracting match Title\n",
    "match=[i.text.strip(' -') for i in driver.find_elements(By.XPATH,'//span[@class=\"matchOrderText ng-binding ng-scope\"]')]\n",
    "\n",
    "#Extracting Series\n",
    "series = [i.text for i in driver.find_elements(By.XPATH,'//h5[@class=\"match-tournament-name ng-binding\"]')]\n",
    "\n",
    "#Extracting Place\n",
    "place = [i.text.split(' -')[1] for i in driver.find_elements(By.XPATH,'//div[@class=\"match-place ng-scope\"]')]\n",
    "\n",
    "# Extracting Date\n",
    "date = [i.text for i in driver.find_elements(By.XPATH,'//div[@class=\"match-dates ng-binding\"]')]\n",
    "\n",
    "# Extracting Time\n",
    "time = [i.text for i in driver.find_elements(By.XPATH,'//div[@class=\"match-time no-margin ng-binding\"]')]\n",
    "\n",
    "driver.close()\n",
    "\n",
    "print(len(match),len(series),len(place),len(date),len(time))\n",
    "\n",
    "internationalfixtures=pd.DataFrame({\n",
    "    \"Match Title\": match,\n",
    "    \"Series\": series,\n",
    "    \"Place\": place,\n",
    "    \"Date\": date,\n",
    "    \"Time\":time\n",
    "})\n",
    "internationalfixtures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b1aaa3",
   "metadata": {},
   "source": [
    "#### 3. Scrape the details of State-wise GDP of India from statisticstime.com. Url = http://statisticstimes.com/ You have to find following details:\n",
    "\n",
    "* Rank\n",
    "* State\n",
    "* GSDP(18-19)- at current prices\n",
    "* GSDP(19-20)- at current prices\n",
    "* Share(18-19)\n",
    "* GDP($ billion)\n",
    "\n",
    "** Note: - From statisticstimes home page you have to reach to economy page through code.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7326091a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "import pandas as pd\n",
    "import selenium                                  \n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver                   \n",
    "from selenium.webdriver.common.by import By      \n",
    "\n",
    "import warnings                                  \n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import time                                      \n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "\n",
    "#Importing required exceptions which needs to be handled\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException, ElementClickInterceptedException\n",
    "\n",
    "# Let's Install automated chrome browser and connect it to web driver\n",
    "driver = webdriver.Chrome(service=Service())\n",
    "\n",
    "#maximise the window\n",
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab3c3095",
   "metadata": {},
   "outputs": [],
   "source": [
    "#opening the website page\n",
    "driver.get(\"https://www.statisticstimes.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b6d66b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clicking Economy\n",
    "economy=driver.find_element(By.XPATH,'/html/body/div[2]/div[1]/div[2]/div[2]/button')\n",
    "economy.click()\n",
    "\n",
    "#Clicking on India\n",
    "india=driver.find_element(By.XPATH,'//div[@class=\"dropdown-content\"]/a[3]')\n",
    "india.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7784f6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "GDP=driver.find_element(By.XPATH,'/html/body/div[2]/div[2]/div[2]/ul/li[1]/a')\n",
    "GDP.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0e2b5e4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>State</th>\n",
       "      <th>GSDP 2019-20(Cr INR at Current Price)</th>\n",
       "      <th>GSDP 2018-19(Cr INR at Current Price)</th>\n",
       "      <th>Share(%)</th>\n",
       "      <th>GDP($billion)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>-</td>\n",
       "      <td>2,632,792</td>\n",
       "      <td>13.94%</td>\n",
       "      <td>399.921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Tamil Nadu</td>\n",
       "      <td>1,845,853</td>\n",
       "      <td>1,630,208</td>\n",
       "      <td>8.63%</td>\n",
       "      <td>247.629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>1,687,818</td>\n",
       "      <td>1,584,764</td>\n",
       "      <td>8.39%</td>\n",
       "      <td>240.726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Gujarat</td>\n",
       "      <td>-</td>\n",
       "      <td>1,502,899</td>\n",
       "      <td>7.96%</td>\n",
       "      <td>228.290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>1,631,977</td>\n",
       "      <td>1,493,127</td>\n",
       "      <td>7.91%</td>\n",
       "      <td>226.806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>West Bengal</td>\n",
       "      <td>1,253,832</td>\n",
       "      <td>1,089,898</td>\n",
       "      <td>5.77%</td>\n",
       "      <td>165.556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Rajasthan</td>\n",
       "      <td>1,020,989</td>\n",
       "      <td>942,586</td>\n",
       "      <td>4.99%</td>\n",
       "      <td>143.179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>972,782</td>\n",
       "      <td>862,957</td>\n",
       "      <td>4.57%</td>\n",
       "      <td>131.083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Telangana</td>\n",
       "      <td>969,604</td>\n",
       "      <td>861,031</td>\n",
       "      <td>4.56%</td>\n",
       "      <td>130.791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Madhya Pradesh</td>\n",
       "      <td>906,672</td>\n",
       "      <td>809,592</td>\n",
       "      <td>4.29%</td>\n",
       "      <td>122.977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>Kerala</td>\n",
       "      <td>-</td>\n",
       "      <td>781,653</td>\n",
       "      <td>4.14%</td>\n",
       "      <td>118.733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>856,112</td>\n",
       "      <td>774,870</td>\n",
       "      <td>4.10%</td>\n",
       "      <td>117.703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>Haryana</td>\n",
       "      <td>831,610</td>\n",
       "      <td>734,163</td>\n",
       "      <td>3.89%</td>\n",
       "      <td>111.519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>Bihar</td>\n",
       "      <td>611,804</td>\n",
       "      <td>530,363</td>\n",
       "      <td>2.81%</td>\n",
       "      <td>80.562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>Punjab</td>\n",
       "      <td>574,760</td>\n",
       "      <td>526,376</td>\n",
       "      <td>2.79%</td>\n",
       "      <td>79.957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>Odisha</td>\n",
       "      <td>521,275</td>\n",
       "      <td>487,805</td>\n",
       "      <td>2.58%</td>\n",
       "      <td>74.098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>Assam</td>\n",
       "      <td>-</td>\n",
       "      <td>315,881</td>\n",
       "      <td>1.67%</td>\n",
       "      <td>47.982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>Chhattisgarh</td>\n",
       "      <td>329,180</td>\n",
       "      <td>304,063</td>\n",
       "      <td>1.61%</td>\n",
       "      <td>46.187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>Jharkhand</td>\n",
       "      <td>328,598</td>\n",
       "      <td>297,204</td>\n",
       "      <td>1.57%</td>\n",
       "      <td>45.145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>Uttarakhand</td>\n",
       "      <td>-</td>\n",
       "      <td>245,895</td>\n",
       "      <td>1.30%</td>\n",
       "      <td>37.351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>Jammu &amp; Kashmir</td>\n",
       "      <td>-</td>\n",
       "      <td>155,956</td>\n",
       "      <td>0.83%</td>\n",
       "      <td>23.690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>Himachal Pradesh</td>\n",
       "      <td>165,472</td>\n",
       "      <td>153,845</td>\n",
       "      <td>0.81%</td>\n",
       "      <td>23.369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>Goa</td>\n",
       "      <td>80,449</td>\n",
       "      <td>73,170</td>\n",
       "      <td>0.39%</td>\n",
       "      <td>11.115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>Tripura</td>\n",
       "      <td>55,984</td>\n",
       "      <td>49,845</td>\n",
       "      <td>0.26%</td>\n",
       "      <td>7.571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>Chandigarh</td>\n",
       "      <td>-</td>\n",
       "      <td>42,114</td>\n",
       "      <td>0.22%</td>\n",
       "      <td>6.397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>Puducherry</td>\n",
       "      <td>38,253</td>\n",
       "      <td>34,433</td>\n",
       "      <td>0.18%</td>\n",
       "      <td>5.230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>Meghalaya</td>\n",
       "      <td>36,572</td>\n",
       "      <td>33,481</td>\n",
       "      <td>0.18%</td>\n",
       "      <td>5.086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>Sikkim</td>\n",
       "      <td>32,496</td>\n",
       "      <td>28,723</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>4.363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>Manipur</td>\n",
       "      <td>31,790</td>\n",
       "      <td>27,870</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>4.233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>Nagaland</td>\n",
       "      <td>-</td>\n",
       "      <td>27,283</td>\n",
       "      <td>0.14%</td>\n",
       "      <td>4.144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31</td>\n",
       "      <td>Arunachal Pradesh</td>\n",
       "      <td>-</td>\n",
       "      <td>24,603</td>\n",
       "      <td>0.13%</td>\n",
       "      <td>3.737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32</td>\n",
       "      <td>Mizoram</td>\n",
       "      <td>26,503</td>\n",
       "      <td>22,287</td>\n",
       "      <td>0.12%</td>\n",
       "      <td>3.385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33</td>\n",
       "      <td>Andaman &amp; Nicobar Islands</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                      State GSDP 2019-20(Cr INR at Current Price)  \\\n",
       "0     1                Maharashtra                                     -   \n",
       "1     2                 Tamil Nadu                             1,845,853   \n",
       "2     3              Uttar Pradesh                             1,687,818   \n",
       "3     4                    Gujarat                                     -   \n",
       "4     5                  Karnataka                             1,631,977   \n",
       "5     6                West Bengal                             1,253,832   \n",
       "6     7                  Rajasthan                             1,020,989   \n",
       "7     8             Andhra Pradesh                               972,782   \n",
       "8     9                  Telangana                               969,604   \n",
       "9    10             Madhya Pradesh                               906,672   \n",
       "10   11                     Kerala                                     -   \n",
       "11   12                      Delhi                               856,112   \n",
       "12   13                    Haryana                               831,610   \n",
       "13   14                      Bihar                               611,804   \n",
       "14   15                     Punjab                               574,760   \n",
       "15   16                     Odisha                               521,275   \n",
       "16   17                      Assam                                     -   \n",
       "17   18               Chhattisgarh                               329,180   \n",
       "18   19                  Jharkhand                               328,598   \n",
       "19   20                Uttarakhand                                     -   \n",
       "20   21            Jammu & Kashmir                                     -   \n",
       "21   22           Himachal Pradesh                               165,472   \n",
       "22   23                        Goa                                80,449   \n",
       "23   24                    Tripura                                55,984   \n",
       "24   25                 Chandigarh                                     -   \n",
       "25   26                 Puducherry                                38,253   \n",
       "26   27                  Meghalaya                                36,572   \n",
       "27   28                     Sikkim                                32,496   \n",
       "28   29                    Manipur                                31,790   \n",
       "29   30                   Nagaland                                     -   \n",
       "30   31          Arunachal Pradesh                                     -   \n",
       "31   32                    Mizoram                                26,503   \n",
       "32   33  Andaman & Nicobar Islands                                     -   \n",
       "\n",
       "   GSDP 2018-19(Cr INR at Current Price) Share(%) GDP($billion)  \n",
       "0                              2,632,792   13.94%       399.921  \n",
       "1                              1,630,208    8.63%       247.629  \n",
       "2                              1,584,764    8.39%       240.726  \n",
       "3                              1,502,899    7.96%       228.290  \n",
       "4                              1,493,127    7.91%       226.806  \n",
       "5                              1,089,898    5.77%       165.556  \n",
       "6                                942,586    4.99%       143.179  \n",
       "7                                862,957    4.57%       131.083  \n",
       "8                                861,031    4.56%       130.791  \n",
       "9                                809,592    4.29%       122.977  \n",
       "10                               781,653    4.14%       118.733  \n",
       "11                               774,870    4.10%       117.703  \n",
       "12                               734,163    3.89%       111.519  \n",
       "13                               530,363    2.81%        80.562  \n",
       "14                               526,376    2.79%        79.957  \n",
       "15                               487,805    2.58%        74.098  \n",
       "16                               315,881    1.67%        47.982  \n",
       "17                               304,063    1.61%        46.187  \n",
       "18                               297,204    1.57%        45.145  \n",
       "19                               245,895    1.30%        37.351  \n",
       "20                               155,956    0.83%        23.690  \n",
       "21                               153,845    0.81%        23.369  \n",
       "22                                73,170    0.39%        11.115  \n",
       "23                                49,845    0.26%         7.571  \n",
       "24                                42,114    0.22%         6.397  \n",
       "25                                34,433    0.18%         5.230  \n",
       "26                                33,481    0.18%         5.086  \n",
       "27                                28,723    0.15%         4.363  \n",
       "28                                27,870    0.15%         4.233  \n",
       "29                                27,283    0.14%         4.144  \n",
       "30                                24,603    0.13%         3.737  \n",
       "31                                22,287    0.12%         3.385  \n",
       "32                                     -        -             -  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Extracting the details\n",
    "rank = []\n",
    "state = []\n",
    "gsdp_18 = []\n",
    "gsdp_19 = []\n",
    "shares = []\n",
    "gdp = []\n",
    "\n",
    "#Extracting the rank details\n",
    "try:\n",
    "    rank_tags = driver.find_elements(By.XPATH,\"//div[@id = 'table_id_wrapper']/table/tbody/tr/td[1]\")\n",
    "    for ra in rank_tags:\n",
    "        rank.append(ra.text)\n",
    "except NoSuchElementException:\n",
    "    Company.append('NA')\n",
    "    \n",
    "#Extracting state name details\n",
    "try:\n",
    "    state_tags = driver.find_elements(By.XPATH,\"//div[@id = 'table_id_wrapper']/table/tbody/tr/td[2]\")\n",
    "    for st in state_tags:\n",
    "        state.append(st.text)\n",
    "except NoSuchElementException:\n",
    "    Company.append('NA')\n",
    "\n",
    "#Extracting gsdp 2019-20\n",
    "try:\n",
    "    gsdp_19_tags = driver.find_elements(By.XPATH,\"//div[@id = 'table_id_wrapper']/table/tbody/tr/td[3]\")\n",
    "    for g in gsdp_19_tags:\n",
    "        gsdp_19.append(g.text)\n",
    "except NoSuchElementException:\n",
    "    Company.append('NA')\n",
    "\n",
    "#Extracting gsdp 2018-19\n",
    "try:\n",
    "    gsdp_18_tags = driver.find_elements(By.XPATH,\"//div[@id = 'table_id_wrapper']/table/tbody/tr/td[4]\")\n",
    "    for gs in gsdp_18_tags:\n",
    "        gsdp_18.append(gs.text)\n",
    "except NoSuchElementException:\n",
    "    Company.append('NA')\n",
    "    \n",
    "#Extracting share details\n",
    "try:\n",
    "    shares_tags = driver.find_elements(By.XPATH,\"//div[@id = 'table_id_wrapper']/table/tbody/tr/td[5]\")\n",
    "    for sh in shares_tags:\n",
    "        shares.append(sh.text)\n",
    "except NoSuchElementException:\n",
    "    Company.append('NA')\n",
    "\n",
    "#Extracting GDP details\n",
    "try:\n",
    "    gdp_tags = driver.find_elements(By.XPATH,\"//div[@id = 'table_id_wrapper']/table/tbody/tr/td[6]\")\n",
    "    for gd in gdp_tags:\n",
    "        gdp.append(gd.text)\n",
    "except NoSuchElementException:\n",
    "    Company.append('NA')\n",
    "\n",
    "gdp_india = pd.DataFrame({'Rank':rank,'State':state,'GSDP 2019-20(Cr INR at Current Price)':gsdp_19,'GSDP 2018-19(Cr INR at Current Price)':gsdp_18,'Share(%)':shares,'GDP($billion)':gdp})\n",
    "gdp_india"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc49f674",
   "metadata": {},
   "source": [
    "#### 4. Scrape the details of trending repositories on Github.com. Url = https://github.com/ You have to find the following details:\n",
    "\n",
    "* Repository title\n",
    "* Repository description\n",
    "* Contributors count\n",
    "* Language used \n",
    "\n",
    "**Note: - From the home page you have to click on the trending option from Explore menu through code.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "95a80618",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "import pandas as pd\n",
    "import selenium                                  \n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver                   \n",
    "from selenium.webdriver.common.by import By      \n",
    "\n",
    "import warnings                                  \n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import time                                      \n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "\n",
    "#Importing required exceptions which needs to be handled\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException, ElementClickInterceptedException\n",
    "\n",
    "# Let's Install automated chrome browser and connect it to web driver\n",
    "driver = webdriver.Chrome(service=Service())\n",
    "\n",
    "#maximise the window\n",
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5e76ca81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#opening the website page\n",
    "driver.get(\"https://github.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "59435a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clicking Open Source\n",
    "source =driver.find_element(By.XPATH,'/html/body/div[1]/div[1]/header/div/div[2]/div/nav/ul/li[3]/button')\n",
    "source.click()\n",
    "\n",
    "#clicking Trending\n",
    "trending=driver.find_element(By.XPATH,'/html/body/div[1]/div[1]/header/div/div[2]/div/nav/ul/li[3]/div/div[3]/ul/li[2]/a')\n",
    "trending.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7cef670a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 25 25 25\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Repository Title</th>\n",
       "      <th>Repository Description</th>\n",
       "      <th>Contributors Count</th>\n",
       "      <th>Language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>joonspk-research / generative_agents</td>\n",
       "      <td>Generative Agents: Interactive Simulacra of Hu...</td>\n",
       "      <td>8,766</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>modelscope / facechain</td>\n",
       "      <td>FaceChain is a deep-learning toolchain for gen...</td>\n",
       "      <td>766</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>phoboslab / wipeout-rewrite</td>\n",
       "      <td>-</td>\n",
       "      <td>439</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>clockworklabs / SpacetimeDB</td>\n",
       "      <td>Multiplayer at the speed of light</td>\n",
       "      <td>1,871</td>\n",
       "      <td>Rust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>yt-dlp / yt-dlp</td>\n",
       "      <td>A youtube-dl fork with additional features and...</td>\n",
       "      <td>53,376</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>id-Software / quake2-rerelease-dll</td>\n",
       "      <td>-</td>\n",
       "      <td>1,431</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>huggingface / candle</td>\n",
       "      <td>Minimalist ML framework for Rust</td>\n",
       "      <td>6,581</td>\n",
       "      <td>Rust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>TheAlgorithms / Python</td>\n",
       "      <td>All Algorithms implemented in Python</td>\n",
       "      <td>164,132</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>bitcoin / bitcoin</td>\n",
       "      <td>Bitcoin Core integration/staging tree</td>\n",
       "      <td>70,814</td>\n",
       "      <td>C++</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Plachtaa / VITS-fast-fine-tuning</td>\n",
       "      <td>This repo is a pipeline of VITS finetuning for...</td>\n",
       "      <td>2,619</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>graphdeco-inria / gaussian-splatting</td>\n",
       "      <td>Original reference implementation of \"3D Gauss...</td>\n",
       "      <td>1,102</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>FlowiseAI / Flowise</td>\n",
       "      <td>Drag &amp; drop UI to build your customized LLM flow</td>\n",
       "      <td>13,605</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>binhnguyennus / awesome-scalability</td>\n",
       "      <td>The Patterns of Scalable, Reliable, and Perfor...</td>\n",
       "      <td>46,707</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>PeiQi0 / PeiQi-WIKI-Book</td>\n",
       "      <td>面向网络安全从业者的知识文库🍃</td>\n",
       "      <td>2,589</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>DeBankDeFi / DeBankChain</td>\n",
       "      <td>-</td>\n",
       "      <td>166</td>\n",
       "      <td>Go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>taikoxyz / taiko-mono</td>\n",
       "      <td>A decentralized, Ethereum-equivalent ZK-Rollup. 🥁</td>\n",
       "      <td>1,887</td>\n",
       "      <td>HTML</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>521xueweihan / HelloGitHub</td>\n",
       "      <td>分享 GitHub 上有趣、入门级的开源项目。Share interesting, entr...</td>\n",
       "      <td>72,766</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>homanp / superagent</td>\n",
       "      <td>🥷 Superagent - Build, deploy, and manage LLM-p...</td>\n",
       "      <td>2,122</td>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>PaperMC / Folia</td>\n",
       "      <td>Fork of Paper which adds regionised multithrea...</td>\n",
       "      <td>2,491</td>\n",
       "      <td>Kotlin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ytdl-org / youtube-dl</td>\n",
       "      <td>Command-line program to download videos from Y...</td>\n",
       "      <td>122,503</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>YBIFoundation / Fundamental</td>\n",
       "      <td>Jupyter Notebook</td>\n",
       "      <td>677</td>\n",
       "      <td>Jupyter Notebook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>libsdl-org / SDL</td>\n",
       "      <td>Simple Directmedia Layer</td>\n",
       "      <td>6,303</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Infisical / infisical</td>\n",
       "      <td>♾ Infisical is an open-source, end-to-end encr...</td>\n",
       "      <td>8,222</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>AUTOMATIC1111 / stable-diffusion-webui</td>\n",
       "      <td>Stable Diffusion web UI</td>\n",
       "      <td>96,768</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>MustardChef / WSABuilds</td>\n",
       "      <td>Run Windows Subsystem For Android on your Wind...</td>\n",
       "      <td>2,363</td>\n",
       "      <td>Shell</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Repository Title  \\\n",
       "0     joonspk-research / generative_agents   \n",
       "1                   modelscope / facechain   \n",
       "2              phoboslab / wipeout-rewrite   \n",
       "3              clockworklabs / SpacetimeDB   \n",
       "4                          yt-dlp / yt-dlp   \n",
       "5       id-Software / quake2-rerelease-dll   \n",
       "6                     huggingface / candle   \n",
       "7                   TheAlgorithms / Python   \n",
       "8                        bitcoin / bitcoin   \n",
       "9         Plachtaa / VITS-fast-fine-tuning   \n",
       "10    graphdeco-inria / gaussian-splatting   \n",
       "11                     FlowiseAI / Flowise   \n",
       "12     binhnguyennus / awesome-scalability   \n",
       "13                PeiQi0 / PeiQi-WIKI-Book   \n",
       "14                DeBankDeFi / DeBankChain   \n",
       "15                   taikoxyz / taiko-mono   \n",
       "16              521xueweihan / HelloGitHub   \n",
       "17                     homanp / superagent   \n",
       "18                         PaperMC / Folia   \n",
       "19                   ytdl-org / youtube-dl   \n",
       "20             YBIFoundation / Fundamental   \n",
       "21                        libsdl-org / SDL   \n",
       "22                   Infisical / infisical   \n",
       "23  AUTOMATIC1111 / stable-diffusion-webui   \n",
       "24                 MustardChef / WSABuilds   \n",
       "\n",
       "                               Repository Description Contributors Count  \\\n",
       "0   Generative Agents: Interactive Simulacra of Hu...              8,766   \n",
       "1   FaceChain is a deep-learning toolchain for gen...                766   \n",
       "2                                                   -                439   \n",
       "3                   Multiplayer at the speed of light              1,871   \n",
       "4   A youtube-dl fork with additional features and...             53,376   \n",
       "5                                                   -              1,431   \n",
       "6                    Minimalist ML framework for Rust              6,581   \n",
       "7                All Algorithms implemented in Python            164,132   \n",
       "8               Bitcoin Core integration/staging tree             70,814   \n",
       "9   This repo is a pipeline of VITS finetuning for...              2,619   \n",
       "10  Original reference implementation of \"3D Gauss...              1,102   \n",
       "11   Drag & drop UI to build your customized LLM flow             13,605   \n",
       "12  The Patterns of Scalable, Reliable, and Perfor...             46,707   \n",
       "13                                    面向网络安全从业者的知识文库🍃              2,589   \n",
       "14                                                  -                166   \n",
       "15  A decentralized, Ethereum-equivalent ZK-Rollup. 🥁              1,887   \n",
       "16  分享 GitHub 上有趣、入门级的开源项目。Share interesting, entr...             72,766   \n",
       "17  🥷 Superagent - Build, deploy, and manage LLM-p...              2,122   \n",
       "18  Fork of Paper which adds regionised multithrea...              2,491   \n",
       "19  Command-line program to download videos from Y...            122,503   \n",
       "20                                   Jupyter Notebook                677   \n",
       "21                           Simple Directmedia Layer              6,303   \n",
       "22  ♾ Infisical is an open-source, end-to-end encr...              8,222   \n",
       "23                            Stable Diffusion web UI             96,768   \n",
       "24  Run Windows Subsystem For Android on your Wind...              2,363   \n",
       "\n",
       "            Language  \n",
       "0                  -  \n",
       "1             Python  \n",
       "2                  C  \n",
       "3               Rust  \n",
       "4             Python  \n",
       "5                  C  \n",
       "6               Rust  \n",
       "7             Python  \n",
       "8                C++  \n",
       "9             Python  \n",
       "10            Python  \n",
       "11        TypeScript  \n",
       "12                 -  \n",
       "13                 -  \n",
       "14                Go  \n",
       "15              HTML  \n",
       "16            Python  \n",
       "17        JavaScript  \n",
       "18            Kotlin  \n",
       "19            Python  \n",
       "20  Jupyter Notebook  \n",
       "21                 C  \n",
       "22        TypeScript  \n",
       "23            Python  \n",
       "24             Shell  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Extracting title\n",
    "title=[i.text for i in driver.find_elements(By.XPATH,'//h2[@class=\"h3 lh-condensed\"]')]\n",
    "\n",
    "#Extracting Description\n",
    "description = []\n",
    "\n",
    "for item in driver.find_elements(By.XPATH, '//article[@class=\"Box-row\"]'):\n",
    "    try:\n",
    "        des = item.find_element(By.XPATH, './/p[@class=\"col-9 color-fg-muted my-1 pr-4\"]')\n",
    "        description.append(des.text)\n",
    "    except NoSuchElementException:\n",
    "        description.append('-')\n",
    "        \n",
    "#Extracting Contributors count\n",
    "count=[i.text for i in driver.find_elements(By.XPATH,'//div[@class=\"f6 color-fg-muted mt-2\"]/a')]\n",
    "contri=count[::2]\n",
    "\n",
    "#Extracting Language\n",
    "lang = []\n",
    "for items in driver.find_elements(By.XPATH,'//div[@class=\"f6 color-fg-muted mt-2\"]'):\n",
    "    try:\n",
    "        l= items.find_element(By.XPATH,'./span/span[2]')\n",
    "        lang.append(l.text)\n",
    "    except NoSuchElementException:\n",
    "        lang.append('-')\n",
    "        \n",
    "driver.close()\n",
    "print(len(title), len(description), len(contri), len(lang))\n",
    "\n",
    "#Converting it into DataFrame:\n",
    "trending_repositories = pd.DataFrame({\n",
    "    \"Repository Title\":title,\n",
    "    \"Repository Description\": description,\n",
    "    \"Contributors Count\" : contri,\n",
    "    \"Language\" : lang\n",
    "})\n",
    "\n",
    "trending_repositories"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f240e85",
   "metadata": {},
   "source": [
    "#### 5. Scrape the details of top 100 songs on billiboard.com. Url = https:/www.billboard.com/ You have to find the following details:\n",
    "\n",
    "* Song name\n",
    "* Artist name\n",
    "* Last week rank\n",
    "* Peak rank\n",
    "* Weeks on board\n",
    "\n",
    "**Note: - From the home page you have to click on the charts option then hot 100-page link through code**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9320bfd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "import pandas as pd\n",
    "import selenium                                  \n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver                   \n",
    "from selenium.webdriver.common.by import By      \n",
    "\n",
    "import warnings                                  \n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import time                                      \n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "\n",
    "#Importing required exceptions which needs to be handled\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException, ElementClickInterceptedException\n",
    "\n",
    "# Let's Install automated chrome browser and connect it to web driver\n",
    "driver = webdriver.Chrome(service=Service())\n",
    "\n",
    "#maximise the window\n",
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dac7bf68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#opening the website page\n",
    "driver.get(\"https://www.billboard.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "becb68b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clicking on the menu\n",
    "menu=driver.find_element(By.XPATH,'/html/body/div[3]/header/div/div[2]/div/div/div[1]/div[1]/button')\n",
    "menu.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9000b0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clicking top 100\n",
    "top = driver.find_element(By.XPATH,'/html/body/div[3]/div[9]/div/div/div/ul/li[1]/ul/li[2]/a')\n",
    "top.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4d34a2f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Song name</th>\n",
       "      <th>Artist Name</th>\n",
       "      <th>Last Weak Rank</th>\n",
       "      <th>Peak Rank</th>\n",
       "      <th>Weeks on Chart</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Last Night</td>\n",
       "      <td>Morgan Wallen</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fast Car</td>\n",
       "      <td>Luke Combs</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Meltdown</td>\n",
       "      <td>Travis Scott Featuring Drake</td>\n",
       "      <td>-</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cruel Summer</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FE!N</td>\n",
       "      <td>Travis Scott Featuring Playboi Carti</td>\n",
       "      <td>-</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Oh U Went</td>\n",
       "      <td>Young Thug Featuring Drake</td>\n",
       "      <td>66</td>\n",
       "      <td>19</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>ICU</td>\n",
       "      <td>Coco Jones</td>\n",
       "      <td>71</td>\n",
       "      <td>62</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Pound Town 2</td>\n",
       "      <td>Sexyy Red &amp; Tay Keith &amp; Nicki Minaj</td>\n",
       "      <td>74</td>\n",
       "      <td>66</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Bzrp Music Sessions, Vol. 55</td>\n",
       "      <td>Bizarrap &amp; Peso Pluma</td>\n",
       "      <td>72</td>\n",
       "      <td>31</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Johnny Dang</td>\n",
       "      <td>That Mexican OT, Paul Wall &amp; DRODi</td>\n",
       "      <td>96</td>\n",
       "      <td>96</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Song name                           Artist Name  \\\n",
       "0                     Last Night                         Morgan Wallen   \n",
       "1                       Fast Car                            Luke Combs   \n",
       "2                       Meltdown          Travis Scott Featuring Drake   \n",
       "3                   Cruel Summer                          Taylor Swift   \n",
       "4                           FE!N  Travis Scott Featuring Playboi Carti   \n",
       "..                           ...                                   ...   \n",
       "95                     Oh U Went            Young Thug Featuring Drake   \n",
       "96                           ICU                            Coco Jones   \n",
       "97                  Pound Town 2   Sexyy Red & Tay Keith & Nicki Minaj   \n",
       "98  Bzrp Music Sessions, Vol. 55                 Bizarrap & Peso Pluma   \n",
       "99                   Johnny Dang    That Mexican OT, Paul Wall & DRODi   \n",
       "\n",
       "   Last Weak Rank Peak Rank Weeks on Chart  \n",
       "0               2         1             27  \n",
       "1               3         2             19  \n",
       "2               -         3              1  \n",
       "3               6         4             13  \n",
       "4               -         5              1  \n",
       "..            ...       ...            ...  \n",
       "95             66        19              6  \n",
       "96             71        62             18  \n",
       "97             74        66              9  \n",
       "98             72        31              9  \n",
       "99             96        96              3  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Extracting Required Data\n",
    "data=[i.text.split('\\n') for i in driver.find_elements(By.XPATH,'//li[@class=\"lrv-u-width-100p\"]')]\n",
    "\n",
    "driver.close()\n",
    "\n",
    "#Creating DataFrame:\n",
    "columns = ['Song name', 'Artist Name', 'Last Weak Rank', 'Peak Rank', 'Weeks on Chart']\n",
    "\n",
    "Top100 = pd.DataFrame(data, columns=columns)\n",
    "Top100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c8adaf",
   "metadata": {},
   "source": [
    "#### 6. Scrape the details of Highest selling novels.compare\n",
    "* Book name\n",
    "* Author name\n",
    "* Volumes sold\n",
    "* Publisher\n",
    "* Genre\n",
    "\n",
    "Url = https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-greyYou have to find the following details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "489b1ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "import pandas as pd\n",
    "import selenium                                  \n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver                   \n",
    "from selenium.webdriver.common.by import By      \n",
    "\n",
    "import warnings                                  \n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import time                                      \n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "\n",
    "#Importing required exceptions which needs to be handled\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException, ElementClickInterceptedException\n",
    "\n",
    "# Let's Install automated chrome browser and connect it to web driver\n",
    "driver = webdriver.Chrome(service=Service())\n",
    "\n",
    "#maximise the window\n",
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f2532377",
   "metadata": {},
   "outputs": [],
   "source": [
    "#opening the website page\n",
    "driver.get(\"https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "71be95ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100 100 100 100\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book Name</th>\n",
       "      <th>Author Name</th>\n",
       "      <th>Volumes sold</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Da Vinci Code,The</td>\n",
       "      <td>Brown, Dan</td>\n",
       "      <td>5,094,805</td>\n",
       "      <td>Transworld</td>\n",
       "      <td>Crime, Thriller &amp; Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Harry Potter and the Deathly Hallows</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,475,152</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Harry Potter and the Philosopher's Stone</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,200,654</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Harry Potter and the Order of the Phoenix</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,179,479</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fifty Shades of Grey</td>\n",
       "      <td>James, E. L.</td>\n",
       "      <td>3,758,936</td>\n",
       "      <td>Random House</td>\n",
       "      <td>Romance &amp; Sagas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Ghost,The</td>\n",
       "      <td>Harris, Robert</td>\n",
       "      <td>807,311</td>\n",
       "      <td>Random House</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Happy Days with the Naked Chef</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>794,201</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Hunger Games,The:Hunger Games Trilogy</td>\n",
       "      <td>Collins, Suzanne</td>\n",
       "      <td>792,187</td>\n",
       "      <td>Scholastic Ltd.</td>\n",
       "      <td>Young Adult Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Lost Boy,The:A Foster Child's Search for the L...</td>\n",
       "      <td>Pelzer, Dave</td>\n",
       "      <td>791,507</td>\n",
       "      <td>Orion</td>\n",
       "      <td>Biography: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Jamie's Ministry of Food:Anyone Can Learn to C...</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>791,095</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Book Name       Author Name  \\\n",
       "0                                   Da Vinci Code,The        Brown, Dan   \n",
       "1                Harry Potter and the Deathly Hallows     Rowling, J.K.   \n",
       "2            Harry Potter and the Philosopher's Stone     Rowling, J.K.   \n",
       "3           Harry Potter and the Order of the Phoenix     Rowling, J.K.   \n",
       "4                                Fifty Shades of Grey      James, E. L.   \n",
       "..                                                ...               ...   \n",
       "95                                          Ghost,The    Harris, Robert   \n",
       "96                     Happy Days with the Naked Chef     Oliver, Jamie   \n",
       "97              Hunger Games,The:Hunger Games Trilogy  Collins, Suzanne   \n",
       "98  Lost Boy,The:A Foster Child's Search for the L...      Pelzer, Dave   \n",
       "99  Jamie's Ministry of Food:Anyone Can Learn to C...     Oliver, Jamie   \n",
       "\n",
       "   Volumes sold        Publisher                        Genre  \n",
       "0     5,094,805       Transworld  Crime, Thriller & Adventure  \n",
       "1     4,475,152       Bloomsbury           Children's Fiction  \n",
       "2     4,200,654       Bloomsbury           Children's Fiction  \n",
       "3     4,179,479       Bloomsbury           Children's Fiction  \n",
       "4     3,758,936     Random House              Romance & Sagas  \n",
       "..          ...              ...                          ...  \n",
       "95      807,311     Random House   General & Literary Fiction  \n",
       "96      794,201          Penguin        Food & Drink: General  \n",
       "97      792,187  Scholastic Ltd.          Young Adult Fiction  \n",
       "98      791,507            Orion           Biography: General  \n",
       "99      791,095          Penguin        Food & Drink: General  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Extracting Book Name\n",
    "book =[i.text for i in driver.find_elements(By.XPATH,'//table[@class=\"in-article sortable\"]/tbody/tr/td[2]')]\n",
    "\n",
    "#Extracting Author Name\n",
    "author = [i.text for i in driver.find_elements(By.XPATH,'//table[@class=\"in-article sortable\"]/tbody/tr/td[3]')]\n",
    "\n",
    "#Extracting Volumes sold\n",
    "vol = [i.text for i in driver.find_elements(By.XPATH,'//table[@class=\"in-article sortable\"]/tbody/tr/td[4]')]\n",
    "\n",
    "#Extracting Publisher\n",
    "pub = [i.text for i in driver.find_elements(By.XPATH,'//table[@class=\"in-article sortable\"]/tbody/tr/td[5]')]\n",
    "\n",
    "#Extracting Genre\n",
    "gen = [i.text for i in driver.find_elements(By.XPATH,'//table[@class=\"in-article sortable\"]/tbody/tr/td[6]')]\n",
    "\n",
    "driver.close()\n",
    "print(len(book),len(author),len(vol),len(pub), len(gen))\n",
    "\n",
    "# Convertingin Dataframe:\n",
    "Highest_selling_novels=pd.DataFrame({\n",
    "    \"Book Name\": book,\n",
    "    \"Author Name\":author,\n",
    "    \"Volumes sold\":vol,\n",
    "    \"Publisher\": pub,\n",
    "    \"Genre\" : gen\n",
    "})\n",
    "\n",
    "Highest_selling_novels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8551539",
   "metadata": {},
   "source": [
    "#### 7. Scrape the details most watched tv series of all time from imdb.com. Url = https://www.imdb.com/list/ls095964455/ You have to find the following details:\n",
    "\n",
    "* Name\n",
    "* Year span\n",
    "* Genre\n",
    "* Run time\n",
    "* Ratings\n",
    "* Votes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9f3b14d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "import pandas as pd\n",
    "import selenium                                  \n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver                   \n",
    "from selenium.webdriver.common.by import By      \n",
    "\n",
    "import warnings                                  \n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import time                                      \n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "\n",
    "#Importing required exceptions which needs to be handled\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException, ElementClickInterceptedException\n",
    "\n",
    "# Let's Install automated chrome browser and connect it to web driver\n",
    "driver = webdriver.Chrome(service=Service())\n",
    "\n",
    "#maximise the window\n",
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6e225844",
   "metadata": {},
   "outputs": [],
   "source": [
    "#opening the website page\n",
    "driver.get(\"https://www.imdb.com/list/ls095964455/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cbd3e591",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100 100 100 100 100\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Year span</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Run time</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Game of Thrones</td>\n",
       "      <td>(2011–2019)</td>\n",
       "      <td>Action, Adventure, Drama</td>\n",
       "      <td>57 min</td>\n",
       "      <td>9.2</td>\n",
       "      <td>2,191,908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stranger Things</td>\n",
       "      <td>(2016–2024)</td>\n",
       "      <td>Drama, Fantasy, Horror</td>\n",
       "      <td>51 min</td>\n",
       "      <td>8.7</td>\n",
       "      <td>1,265,861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Walking Dead</td>\n",
       "      <td>(2010–2022)</td>\n",
       "      <td>Drama, Horror, Thriller</td>\n",
       "      <td>44 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>1,040,492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13 Reasons Why</td>\n",
       "      <td>(2017–2020)</td>\n",
       "      <td>Drama, Mystery, Thriller</td>\n",
       "      <td>60 min</td>\n",
       "      <td>7.5</td>\n",
       "      <td>305,807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The 100</td>\n",
       "      <td>(2014–2020)</td>\n",
       "      <td>Drama, Mystery, Sci-Fi</td>\n",
       "      <td>43 min</td>\n",
       "      <td>7.6</td>\n",
       "      <td>264,893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Reign</td>\n",
       "      <td>(2013–2017)</td>\n",
       "      <td>Drama</td>\n",
       "      <td>42 min</td>\n",
       "      <td>7.5</td>\n",
       "      <td>52,400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>A Series of Unfortunate Events</td>\n",
       "      <td>(2017–2019)</td>\n",
       "      <td>Adventure, Comedy, Drama</td>\n",
       "      <td>50 min</td>\n",
       "      <td>7.8</td>\n",
       "      <td>64,426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Criminal Minds</td>\n",
       "      <td>(2005– )</td>\n",
       "      <td>Crime, Drama, Mystery</td>\n",
       "      <td>42 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>209,987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Scream: The TV Series</td>\n",
       "      <td>(2015–2019)</td>\n",
       "      <td>Comedy, Crime, Drama</td>\n",
       "      <td>45 min</td>\n",
       "      <td>7</td>\n",
       "      <td>43,659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>The Haunting of Hill House</td>\n",
       "      <td>(2018)</td>\n",
       "      <td>Drama, Horror, Mystery</td>\n",
       "      <td>572 min</td>\n",
       "      <td>8.6</td>\n",
       "      <td>263,433</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Name    Year span                     Genre  \\\n",
       "0                  Game of Thrones  (2011–2019)  Action, Adventure, Drama   \n",
       "1                  Stranger Things  (2016–2024)    Drama, Fantasy, Horror   \n",
       "2                 The Walking Dead  (2010–2022)   Drama, Horror, Thriller   \n",
       "3                   13 Reasons Why  (2017–2020)  Drama, Mystery, Thriller   \n",
       "4                          The 100  (2014–2020)    Drama, Mystery, Sci-Fi   \n",
       "..                             ...          ...                       ...   \n",
       "95                           Reign  (2013–2017)                     Drama   \n",
       "96  A Series of Unfortunate Events  (2017–2019)  Adventure, Comedy, Drama   \n",
       "97                  Criminal Minds     (2005– )     Crime, Drama, Mystery   \n",
       "98           Scream: The TV Series  (2015–2019)      Comedy, Crime, Drama   \n",
       "99      The Haunting of Hill House       (2018)    Drama, Horror, Mystery   \n",
       "\n",
       "   Run time Ratings      Votes  \n",
       "0    57 min     9.2  2,191,908  \n",
       "1    51 min     8.7  1,265,861  \n",
       "2    44 min     8.1  1,040,492  \n",
       "3    60 min     7.5    305,807  \n",
       "4    43 min     7.6    264,893  \n",
       "..      ...     ...        ...  \n",
       "95   42 min     7.5     52,400  \n",
       "96   50 min     7.8     64,426  \n",
       "97   42 min     8.1    209,987  \n",
       "98   45 min       7     43,659  \n",
       "99  572 min     8.6    263,433  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Extracting Name:\n",
    "name =[i.text for i in driver.find_elements(By.XPATH,'//h3[@class=\"lister-item-header\"]/a')]\n",
    "\n",
    "# Extracting Year Span\n",
    "year = [i.text for i in driver.find_elements(By.XPATH,'//span[@class=\"lister-item-year text-muted unbold\"]')]\n",
    "\n",
    "#Extracting Genre \n",
    "genre = [i.text for i in driver.find_elements(By.XPATH,'//p[@class=\"text-muted text-small\"]/span[5]')]\n",
    "\n",
    "#Extracting Run time\n",
    "time = [i.text for i in driver.find_elements(By.XPATH,'//p[@class=\"text-muted text-small\"]/span[3]')]\n",
    "\n",
    "#Extracting Rating\n",
    "rating = [i.text for i in driver.find_elements(By.XPATH,'//div[@class=\"ipl-rating-widget\"]/div/span[2]')]\n",
    "\n",
    "#Extracting Votes\n",
    "voting = [i.text for i in driver.find_elements(By.XPATH,'//p[@class=\"text-muted text-small\"][3]/span[2]')]\n",
    "\n",
    "driver.close()\n",
    "print(len(name), len(year), len(genre), len(time), len(rating),len(voting))\n",
    "\n",
    "#Creating DataFrame\n",
    "most_watched_tv_series=pd.DataFrame({\n",
    "    \"Name\": name,\n",
    "    \"Year span\":year,\n",
    "    \"Genre\":genre,\n",
    "    \"Run time\":time,\n",
    "    \"Ratings\":rating,\n",
    "    \"Votes\": voting\n",
    "})\n",
    "most_watched_tv_series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aadc7798",
   "metadata": {},
   "source": [
    "#### 8. Details of Datasets from UCI machine learning repositories. Url = https://archive.ics.uci.edu/ You have to find the following details:\n",
    "\n",
    "* Dataset name\n",
    "* Data type\n",
    "* Task\n",
    "* Attribute type\n",
    "* No of instances\n",
    "* No of attribute\n",
    "* Year\n",
    "\n",
    "**Note: - from the home page you have to go to the Show All Dataset page through code.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e58b62d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "import pandas as pd\n",
    "import selenium                                  \n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver                   \n",
    "from selenium.webdriver.common.by import By      \n",
    "\n",
    "import warnings                                  \n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import time                                      \n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "\n",
    "#Importing required exceptions which needs to be handled\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException, ElementClickInterceptedException\n",
    "\n",
    "# Let's Install automated chrome browser and connect it to web driver\n",
    "driver = webdriver.Chrome(service=Service())\n",
    "\n",
    "#maximise the window\n",
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9209a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#opening the website page\n",
    "driver.get(\"https://archive.ics.uci.edu/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5cf76b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clicking all dataset\n",
    "dataset=driver.find_element(By.XPATH,'/html/body/div/div[1]/div[1]/header/nav/ul/li[1]/a')\n",
    "dataset.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da547f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clicking collapse\n",
    "collapse=driver.find_element(By.XPATH,'//label[@class=\"btn-primary btn-sm btn flex gap-2 rounded-full\"]')\n",
    "collapse.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5799e677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "624 624 624 624 624 624 624\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset Name</th>\n",
       "      <th>Data Type</th>\n",
       "      <th>Task</th>\n",
       "      <th>Attribute Type</th>\n",
       "      <th>No of Instances</th>\n",
       "      <th>No of Attribute</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Iris</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real</td>\n",
       "      <td>150 Instances</td>\n",
       "      <td>4 Attributes</td>\n",
       "      <td>7/1/1988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Heart Disease</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>303 Instances</td>\n",
       "      <td>13 Attributes</td>\n",
       "      <td>7/1/1988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adult</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer</td>\n",
       "      <td>48.84K Instances</td>\n",
       "      <td>14 Attributes</td>\n",
       "      <td>5/1/1996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dry Bean Dataset</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>13.61K Instances</td>\n",
       "      <td>16 Attributes</td>\n",
       "      <td>9/14/2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Diabetes</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Categorical, Integer</td>\n",
       "      <td></td>\n",
       "      <td>20 Attributes</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>PMU-UD</td>\n",
       "      <td>Univariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real</td>\n",
       "      <td>5.18K Instances</td>\n",
       "      <td>9 Attributes</td>\n",
       "      <td>8/5/2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>Moral Reasoner</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Real</td>\n",
       "      <td>202 Instances</td>\n",
       "      <td></td>\n",
       "      <td>6/1/1994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621</th>\n",
       "      <td>Sattriya_Dance_Single_Hand_Gestures Dataset</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Integer</td>\n",
       "      <td>1.45K Instances</td>\n",
       "      <td></td>\n",
       "      <td>7/22/2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>622</th>\n",
       "      <td>DGP2 - The Second Data Generation Program</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Real</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>623</th>\n",
       "      <td>EBL Domain Theories</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Real</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>624 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Dataset Name     Data Type  \\\n",
       "0                                           Iris  Multivariate   \n",
       "1                                  Heart Disease  Multivariate   \n",
       "2                                          Adult  Multivariate   \n",
       "3                               Dry Bean Dataset  Multivariate   \n",
       "4                                       Diabetes                 \n",
       "..                                           ...           ...   \n",
       "619                                       PMU-UD    Univariate   \n",
       "620                               Moral Reasoner                 \n",
       "621  Sattriya_Dance_Single_Hand_Gestures Dataset  Multivariate   \n",
       "622    DGP2 - The Second Data Generation Program                 \n",
       "623                          EBL Domain Theories                 \n",
       "\n",
       "               Task              Attribute Type   No of Instances  \\\n",
       "0    Classification                        Real     150 Instances   \n",
       "1    Classification  Categorical, Integer, Real     303 Instances   \n",
       "2    Classification        Categorical, Integer  48.84K Instances   \n",
       "3    Classification               Integer, Real  13.61K Instances   \n",
       "4                          Categorical, Integer                     \n",
       "..              ...                         ...               ...   \n",
       "619  Classification                        Real   5.18K Instances   \n",
       "620                                        Real     202 Instances   \n",
       "621  Classification                     Integer   1.45K Instances   \n",
       "622                                        Real                     \n",
       "623                                        Real                     \n",
       "\n",
       "    No of Attribute       Year  \n",
       "0      4 Attributes   7/1/1988  \n",
       "1     13 Attributes   7/1/1988  \n",
       "2     14 Attributes   5/1/1996  \n",
       "3     16 Attributes  9/14/2020  \n",
       "4     20 Attributes        N/A  \n",
       "..              ...        ...  \n",
       "619    9 Attributes   8/5/2018  \n",
       "620                   6/1/1994  \n",
       "621                  7/22/2019  \n",
       "622                        N/A  \n",
       "623                        N/A  \n",
       "\n",
       "[624 rows x 7 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name=[]\n",
    "datatype=[]\n",
    "task=[]\n",
    "instances=[]\n",
    "no_attribute=[]\n",
    "attributetype=[]\n",
    "year=[]\n",
    "\n",
    "while True:\n",
    "    \n",
    "    #Extracting Name:\n",
    "    for i in driver.find_elements(By.XPATH,'//h2[@class=\"truncate text-primary\"]'):\n",
    "        name.append(i.text)\n",
    "    \n",
    "    #Extracting DataType\n",
    "    for i in driver.find_elements(By.XPATH,'//div[@class=\"relative col-span-8 sm:col-span-7\"]/div/div[2]'):\n",
    "        datatype.append(i.text)\n",
    "        \n",
    "    #Extracting task\n",
    "    for i in driver.find_elements(By.XPATH,'//div[@class=\"relative col-span-8 sm:col-span-7\"]/div/div[1]'):\n",
    "        task.append(i.text)\n",
    "    \n",
    "    #Extracting attribute\n",
    "    try:\n",
    "        for i in driver.find_elements(By.XPATH,'//tbody[@class=\"border\"]/tr/td[2]'):\n",
    "            attributetype.append(i.text)\n",
    "    except (NoSuchElementException, StaleElementReferenceException):\n",
    "        attributetype.append('N/A')\n",
    "        \n",
    "    #Extracting instances\n",
    "    for i in driver.find_elements(By.XPATH,'//div[@class=\"relative col-span-8 sm:col-span-7\"]/div/div[3]'):\n",
    "        instances.append(i.text)\n",
    "    \n",
    "    #Extracting No of attributes\n",
    "    for i in driver.find_elements(By.XPATH,'//div[@class=\"relative col-span-8 sm:col-span-7\"]/div/div[4]'):\n",
    "        no_attribute.append(i.text)\n",
    "    \n",
    "    #Extracting attribute\n",
    "    for i in driver.find_elements(By.XPATH,'//div[@class=\"grid grid-cols-8 overflow-x-auto\"]'):\n",
    "        try:\n",
    "            a=i.find_element(By.XPATH,'./table/tbody/tr/td[2]')\n",
    "            attributetype.append(a.text)\n",
    "        except NoSuchElementException:\n",
    "            attributetype.append('N/A')\n",
    "    \n",
    "    #Extracting Year\n",
    "    for i in driver.find_elements(By.XPATH,'//div[@class=\"grid grid-cols-8 overflow-x-auto\"]'):\n",
    "        try:\n",
    "            y= i.find_element(By.XPATH,'./table/tbody/tr/td[3]')\n",
    "            year.append(y.text)\n",
    "        except NoSuchElementException:\n",
    "            year.append('N/A')\n",
    "        \n",
    "    #clicking next button\n",
    "    try:\n",
    "        nextButton= driver.find_element(By.XPATH,'//button[@class=\"btn-primary btn-sm btn\"][2]')\n",
    "        nextButton.click()\n",
    "        time.sleep(3)\n",
    "    except (NoSuchElementException, ElementClickInterceptedException):\n",
    "        break\n",
    "\n",
    "driver.close()\n",
    "Attributetype=attributetype[:624]\n",
    "print(len(name),len(datatype),len(task),len(instances),len(no_attribute), len(Attributetype), len(year))\n",
    "\n",
    "#Creating DataFrame:\n",
    "data=pd.DataFrame({\n",
    "    \"Dataset Name\":name,\n",
    "    \"Data Type\":datatype,\n",
    "    \"Task\":task,\n",
    "    \"Attribute Type\":Attributetype,\n",
    "    \"No of Instances\":instances,\n",
    "    \"No of Attribute\":no_attribute,\n",
    "    \"Year\":year})\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d06d352",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
