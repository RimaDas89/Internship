{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01fe94a3",
   "metadata": {},
   "source": [
    "# WEB SCRAPING with BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f903a0",
   "metadata": {},
   "source": [
    "Name: Rima Das\n",
    "Batch: DS2306"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df54146d",
   "metadata": {},
   "source": [
    "### Importing all the reqd Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e1b6451",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3abd788",
   "metadata": {},
   "source": [
    "### **Question: 1** Write a python program to display all the header tags from wikipedia.org and make **data frame.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8d61f01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Headers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Welcome to Wikipedia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>From today's featured article</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Did you know ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>In the news</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>On this day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Today's featured picture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Other areas of Wikipedia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Wikipedia's sister projects</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Wikipedia languages</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Headers\n",
       "0           Welcome to Wikipedia\n",
       "1  From today's featured article\n",
       "2               Did you know ...\n",
       "3                    In the news\n",
       "4                    On this day\n",
       "5       Today's featured picture\n",
       "6       Other areas of Wikipedia\n",
       "7    Wikipedia's sister projects\n",
       "8            Wikipedia languages"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki = requests.get('https://en.wikipedia.org/wiki/Main_Page')\n",
    "wikicontent = BeautifulSoup(wiki.content)\n",
    "\n",
    "headers = []\n",
    "for i in wikicontent.find_all('span',class_=\"mw-headline\"):\n",
    "    headers.append(i.text)\n",
    "    \n",
    "#making dataframe\n",
    "df = pd.DataFrame({'Headers':headers})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e65d4390",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d33da7e3",
   "metadata": {},
   "source": [
    "### **Question: 2** Write s python program to display list of respected former presidents of India(i.e. Name , Term ofoffice) from https://presidentofindia.nic.in/former-presidents.htm and make data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d32ef74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>President_Name</th>\n",
       "      <th>Term_of_office</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Shri Ram Nath Kovind</td>\n",
       "      <td>25 July, 2017 to 25 July, 2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Shri Pranab Mukherjee</td>\n",
       "      <td>25 July, 2012 to 25 July, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Smt Pratibha Devisingh Patil</td>\n",
       "      <td>25 July, 2007 to 25 July, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DR. A.P.J. Abdul Kalam</td>\n",
       "      <td>25 July, 2002 to 25 July, 2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Shri K. R. Narayanan</td>\n",
       "      <td>25 July, 1997 to 25 July, 2002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Dr Shankar Dayal Sharma</td>\n",
       "      <td>25 July, 1992 to 25 July, 1997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Shri R Venkataraman</td>\n",
       "      <td>25 July, 1987 to 25 July, 1992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Giani Zail Singh</td>\n",
       "      <td>25 July, 1982 to 25 July, 1987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Shri Neelam Sanjiva Reddy</td>\n",
       "      <td>25 July, 1977 to 25 July, 1982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Dr. Fakhruddin Ali Ahmed</td>\n",
       "      <td>24 August, 1974 to 11 February, 1977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Shri Varahagiri Venkata Giri</td>\n",
       "      <td>3 May, 1969 to 20 July, 1969 and 24 August, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Dr. Zakir Husain</td>\n",
       "      <td>13 May, 1967 to 3 May, 1969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Dr. Sarvepalli Radhakrishnan</td>\n",
       "      <td>13 May, 1962 to 13 May, 1967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Dr. Rajendra Prasad</td>\n",
       "      <td>26 January, 1950 to 13 May, 1962</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  President_Name  \\\n",
       "0           Shri Ram Nath Kovind   \n",
       "1          Shri Pranab Mukherjee   \n",
       "2   Smt Pratibha Devisingh Patil   \n",
       "3         DR. A.P.J. Abdul Kalam   \n",
       "4           Shri K. R. Narayanan   \n",
       "5        Dr Shankar Dayal Sharma   \n",
       "6            Shri R Venkataraman   \n",
       "7               Giani Zail Singh   \n",
       "8      Shri Neelam Sanjiva Reddy   \n",
       "9       Dr. Fakhruddin Ali Ahmed   \n",
       "10  Shri Varahagiri Venkata Giri   \n",
       "11              Dr. Zakir Husain   \n",
       "12  Dr. Sarvepalli Radhakrishnan   \n",
       "13           Dr. Rajendra Prasad   \n",
       "\n",
       "                                       Term_of_office  \n",
       "0                     25 July, 2017 to 25 July, 2022   \n",
       "1                     25 July, 2012 to 25 July, 2017   \n",
       "2                     25 July, 2007 to 25 July, 2012   \n",
       "3                     25 July, 2002 to 25 July, 2007   \n",
       "4                     25 July, 1997 to 25 July, 2002   \n",
       "5                     25 July, 1992 to 25 July, 1997   \n",
       "6                     25 July, 1987 to 25 July, 1992   \n",
       "7                     25 July, 1982 to 25 July, 1987   \n",
       "8                     25 July, 1977 to 25 July, 1982   \n",
       "9                24 August, 1974 to 11 February, 1977  \n",
       "10   3 May, 1969 to 20 July, 1969 and 24 August, 1...  \n",
       "11                        13 May, 1967 to 3 May, 1969  \n",
       "12                       13 May, 1962 to 13 May, 1967  \n",
       "13                   26 January, 1950 to 13 May, 1962  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "presidents = requests.get('https://presidentofindia.nic.in/former-presidents.htm')\n",
    "soup = BeautifulSoup(presidents.content)\n",
    "\n",
    "#extracting Names\n",
    "names = [i.text for i in soup.find_all('h3')]\n",
    "extract_names = [name.split('(')[0].strip() for name in names]\n",
    "\n",
    "#extracting Terms:\n",
    "terms = [i.text.strip('\\n') for i in soup.find_all('div', class_=\"presidentListing\")]\n",
    "data=[i.split('\\n')[1].split(':')[1] for i in terms]\n",
    "\n",
    "#making DataFrame\n",
    "Former_president = pd.DataFrame({'President_Name': extract_names, 'Term_of_office': data})\n",
    "Former_president"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b8fc23",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba0ad4fa",
   "metadata": {},
   "source": [
    "### **Question: 3** Write a python program to scrape cricket rankings from icc-cricket.com. You have to scrape and make data frame\n",
    "1. Top 10 ODI teams in men’s cricket along with the records for matches, points and rating.\n",
    "2. Top 10 ODI Batsmen along with the records of their team andrating.\n",
    "3. Top 10 ODI bowlers along with the records of their team andrating."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1113c46",
   "metadata": {},
   "source": [
    "#### 1. Top 10 ODI teams in men’s cricket along with the records for matches, points and rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6417d1dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team</th>\n",
       "      <th>Matches</th>\n",
       "      <th>Points</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Australia</td>\n",
       "      <td>23</td>\n",
       "      <td>2,714</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pakistan</td>\n",
       "      <td>20</td>\n",
       "      <td>2,316</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>India</td>\n",
       "      <td>33</td>\n",
       "      <td>3,807</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>New Zealand</td>\n",
       "      <td>27</td>\n",
       "      <td>2,806</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>England</td>\n",
       "      <td>24</td>\n",
       "      <td>2,426</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>South Africa</td>\n",
       "      <td>19</td>\n",
       "      <td>1,910</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>25</td>\n",
       "      <td>2,451</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Sri Lanka</td>\n",
       "      <td>28</td>\n",
       "      <td>2,378</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>13</td>\n",
       "      <td>1,067</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>West Indies</td>\n",
       "      <td>32</td>\n",
       "      <td>2,201</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Team Matches Points Rating\n",
       "0     Australia      23  2,714    118\n",
       "1      Pakistan      20  2,316    116\n",
       "2         India      33  3,807    115\n",
       "3   New Zealand      27  2,806    104\n",
       "4       England      24  2,426    101\n",
       "5  South Africa      19  1,910    101\n",
       "6    Bangladesh      25  2,451     98\n",
       "7     Sri Lanka      28  2,378     85\n",
       "8   Afghanistan      13  1,067     82\n",
       "9   West Indies      32  2,201     69"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get Response\n",
    "page = requests.get('https://www.icc-cricket.com/rankings/mens/team-rankings/odi')\n",
    "\n",
    "#Page Content\n",
    "soup = BeautifulSoup(page.content)\n",
    "\n",
    "# Extracting table\n",
    "table = soup.find('table', class_=\"table\")\n",
    "table.find_all('th')\n",
    " \n",
    "# Extracting Header\n",
    "Head = [i.text.strip('\\n') for i in table.find_all('th')]\n",
    "head = [i.split('\\n')[0] for i in Head]\n",
    "\n",
    "# Extracting Data from table body\n",
    "data = []\n",
    "rows = table.find_all('tr')[1:11]\n",
    "\n",
    "for row in rows:\n",
    "    col = row.find_all('td')\n",
    "    cell = [ele.text.strip() for ele in col]\n",
    "    data.append([ele for ele in cell if ele])\n",
    "\n",
    "#cleaning unnecessary data\n",
    "selected_data = [[i.split('\\n')[0] for i in ele] for ele in data]\n",
    "\n",
    "# Making DataFrame\n",
    "top10_team = pd.DataFrame(data = selected_data, columns = head)\n",
    "top10_team.drop(['Pos'], axis=1, inplace=True)\n",
    "top10_team"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c36164e0",
   "metadata": {},
   "source": [
    "#### 2. Top 10 ODI Batsmen along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c500e12b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>Team</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Babar Azam</td>\n",
       "      <td>PAK</td>\n",
       "      <td>886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Rassie van der Dussen</td>\n",
       "      <td>SA</td>\n",
       "      <td>777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fakhar Zaman</td>\n",
       "      <td>PAK</td>\n",
       "      <td>755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Imam-ul-Haq</td>\n",
       "      <td>PAK</td>\n",
       "      <td>745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Shubman Gill</td>\n",
       "      <td>IND</td>\n",
       "      <td>738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Harry Tector</td>\n",
       "      <td>IRE</td>\n",
       "      <td>726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>David Warner</td>\n",
       "      <td>AUS</td>\n",
       "      <td>726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Virat Kohli</td>\n",
       "      <td>IND</td>\n",
       "      <td>719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Quinton de Kock</td>\n",
       "      <td>SA</td>\n",
       "      <td>718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Rohit Sharma</td>\n",
       "      <td>IND</td>\n",
       "      <td>707</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Player Team Rating\n",
       "0             Babar Azam  PAK    886\n",
       "1  Rassie van der Dussen   SA    777\n",
       "2           Fakhar Zaman  PAK    755\n",
       "3            Imam-ul-Haq  PAK    745\n",
       "4           Shubman Gill  IND    738\n",
       "5           Harry Tector  IRE    726\n",
       "6           David Warner  AUS    726\n",
       "7            Virat Kohli  IND    719\n",
       "8        Quinton de Kock   SA    718\n",
       "9           Rohit Sharma  IND    707"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get Response\n",
    "page = requests.get('https://www.icc-cricket.com/rankings/mens/player-rankings/odi/batting')\n",
    "\n",
    "# Page Content\n",
    "soup = BeautifulSoup(page.content)\n",
    "\n",
    "# extracting table\n",
    "table = soup.find('table', class_=\"table rankings-table\")\n",
    "\n",
    "#extracting table head\n",
    "tablehead = [i.text for i in table.find_all('th')]\n",
    "\n",
    "#extracting table body\n",
    "body = table.find('tbody')\n",
    "rows = table.find_all('tr')[1:11]\n",
    "\n",
    "data = []\n",
    "for row in rows:\n",
    "    col = row.find_all('td')\n",
    "    col = [ele.text.strip() for ele in col]\n",
    "    data.append(col)\n",
    "\n",
    "selected_data = [[i.split('\\n')[0] for i in items] for items in data]\n",
    "\n",
    "# Making DataFrame\n",
    "batting = pd.DataFrame(data = selected_data, columns = tablehead)\n",
    "batting.drop(['Pos', 'Career Best Rating'], axis=1, inplace = True)\n",
    "batting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa509c3a",
   "metadata": {},
   "source": [
    "#### 3. Top 10 ODI bowlers along with the records of their team andrating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f970448",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>Team</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Josh Hazlewood</td>\n",
       "      <td>AUS</td>\n",
       "      <td>705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mohammed Siraj</td>\n",
       "      <td>IND</td>\n",
       "      <td>691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mitchell Starc</td>\n",
       "      <td>AUS</td>\n",
       "      <td>686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Matt Henry</td>\n",
       "      <td>NZ</td>\n",
       "      <td>667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Trent Boult</td>\n",
       "      <td>NZ</td>\n",
       "      <td>660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Adam Zampa</td>\n",
       "      <td>AUS</td>\n",
       "      <td>652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Rashid Khan</td>\n",
       "      <td>AFG</td>\n",
       "      <td>640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Shaheen Afridi</td>\n",
       "      <td>PAK</td>\n",
       "      <td>630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Mujeeb Ur Rahman</td>\n",
       "      <td>AFG</td>\n",
       "      <td>630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Mohammad Nabi</td>\n",
       "      <td>AFG</td>\n",
       "      <td>626</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Player Team Rating\n",
       "0    Josh Hazlewood  AUS    705\n",
       "1    Mohammed Siraj  IND    691\n",
       "2    Mitchell Starc  AUS    686\n",
       "3        Matt Henry   NZ    667\n",
       "4       Trent Boult   NZ    660\n",
       "5        Adam Zampa  AUS    652\n",
       "6       Rashid Khan  AFG    640\n",
       "7    Shaheen Afridi  PAK    630\n",
       "8  Mujeeb Ur Rahman  AFG    630\n",
       "9     Mohammad Nabi  AFG    626"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get Request\n",
    "page = requests.get('https://www.icc-cricket.com/rankings/mens/player-rankings/odi/bowling')\n",
    "\n",
    "# Page content\n",
    "soup = BeautifulSoup(page.content)\n",
    "soup\n",
    "\n",
    "#Extracting Table\n",
    "table = soup.find('table', class_=\"table rankings-table\")\n",
    "\n",
    "#Extracting table head\n",
    "tablehead = table.find_all('th')\n",
    "head = [i.text for i in tablehead]\n",
    "\n",
    "# Extracting rows from Table body\n",
    "rows = table.find_all('tr')[1:11]\n",
    "\n",
    "data = []\n",
    "for row in rows:\n",
    "    col = row.find_all('td')\n",
    "    col =[i.text.strip() for i in col]\n",
    "    data.append(col)\n",
    "\n",
    "cells =[[i.split('\\n')[0] for i in items]for items in data]\n",
    "\n",
    "# Making DataFrame\n",
    "bolwers = pd.DataFrame(data=cells, columns = head )\n",
    "bolwers.drop(['Pos', 'Career Best Rating'], axis=1, inplace=True)\n",
    "bolwers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a7638a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45514316",
   "metadata": {},
   "source": [
    "### **Question: 4** Write a python program to scrape cricket rankings from icc-cricket.com. You have to scrape and make data frame\n",
    "1. Top 10 ODI teams in women’s cricket along with the records for matches, points and rating.\n",
    "2. Top 10 women’s ODI Batting players along with the records of their team and rating.\n",
    "3. Top 10 women’s ODI all-rounder along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6517868a",
   "metadata": {},
   "source": [
    "#### 1. Top 10 ODI teams in women’s cricket along with the records for matches, points and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb7219da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team</th>\n",
       "      <th>Matches</th>\n",
       "      <th>Points</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Australia</td>\n",
       "      <td>21</td>\n",
       "      <td>3,603</td>\n",
       "      <td>172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>England</td>\n",
       "      <td>28</td>\n",
       "      <td>3,342</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>South Africa</td>\n",
       "      <td>26</td>\n",
       "      <td>3,098</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>India</td>\n",
       "      <td>27</td>\n",
       "      <td>2,820</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>New Zealand</td>\n",
       "      <td>28</td>\n",
       "      <td>2,688</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>West Indies</td>\n",
       "      <td>29</td>\n",
       "      <td>2,743</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>14</td>\n",
       "      <td>977</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Sri Lanka</td>\n",
       "      <td>12</td>\n",
       "      <td>820</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Thailand</td>\n",
       "      <td>12</td>\n",
       "      <td>806</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Pakistan</td>\n",
       "      <td>27</td>\n",
       "      <td>1,678</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Ireland</td>\n",
       "      <td>16</td>\n",
       "      <td>605</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Netherlands</td>\n",
       "      <td>10</td>\n",
       "      <td>90</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Team Matches Points Rating\n",
       "0      Australia      21  3,603    172\n",
       "1        England      28  3,342    119\n",
       "2   South Africa      26  3,098    119\n",
       "3          India      27  2,820    104\n",
       "4    New Zealand      28  2,688     96\n",
       "5    West Indies      29  2,743     95\n",
       "6     Bangladesh      14    977     70\n",
       "7      Sri Lanka      12    820     68\n",
       "8       Thailand      12    806     67\n",
       "9       Pakistan      27  1,678     62\n",
       "10       Ireland      16    605     38\n",
       "11   Netherlands      10     90      9\n",
       "12      Zimbabwe      11      0      0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = requests.get('https://www.icc-cricket.com/rankings/womens/team-rankings/odi')\n",
    "soup = BeautifulSoup(url.content)\n",
    "\n",
    "#Extracting table\n",
    "table = soup.find('table', class_=\"table\")\n",
    "table.find_all('th')\n",
    "\n",
    "#extracting Header\n",
    "head = [i.text.strip('\\n') for i in table.find_all('th')]\n",
    "columns = [i.split('\\n')[0] for i in head]\n",
    "\n",
    "# Extracting data from table\n",
    "data = []\n",
    "table_body = soup.find('tbody')\n",
    "rows = table.find_all('tr')[1:]\n",
    "\n",
    "for row in rows:\n",
    "    cols = row.find_all(['td', 'th'])\n",
    "    cols = [ele.text.strip() for ele in cols]\n",
    "    data.append([ele for ele in cols if ele])\n",
    "\n",
    "selected_data = [[i.split('\\n')[0] for i in inner_list] for inner_list in data]\n",
    "\n",
    "# Making DataFrame\n",
    "top_team = pd.DataFrame(data = selected_data, columns = columns)\n",
    "top_team.pop('Pos')\n",
    "top_team"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0fa3d4",
   "metadata": {},
   "source": [
    "#### 2. Top 10 ODI Batsmen along with the records of their team andrating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "239a7872",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>Team</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Australia\\nAUS</td>\n",
       "      <td>21</td>\n",
       "      <td>3,603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>England\\nENG</td>\n",
       "      <td>28</td>\n",
       "      <td>3,342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>South Africa\\nSA</td>\n",
       "      <td>26</td>\n",
       "      <td>3,098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>India\\nIND</td>\n",
       "      <td>27</td>\n",
       "      <td>2,820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>New Zealand\\nNZ</td>\n",
       "      <td>28</td>\n",
       "      <td>2,688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>West Indies\\nWI</td>\n",
       "      <td>29</td>\n",
       "      <td>2,743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Bangladesh\\nBAN</td>\n",
       "      <td>14</td>\n",
       "      <td>977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Sri Lanka\\nSL</td>\n",
       "      <td>12</td>\n",
       "      <td>820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Thailand\\nTHA</td>\n",
       "      <td>12</td>\n",
       "      <td>806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Pakistan\\nPAK</td>\n",
       "      <td>27</td>\n",
       "      <td>1,678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Ireland\\nIRE</td>\n",
       "      <td>16</td>\n",
       "      <td>605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Netherlands\\nNED</td>\n",
       "      <td>10</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Zimbabwe\\nZIM</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Player Team Rating\n",
       "0     Australia\\nAUS   21  3,603\n",
       "1       England\\nENG   28  3,342\n",
       "2   South Africa\\nSA   26  3,098\n",
       "3         India\\nIND   27  2,820\n",
       "4    New Zealand\\nNZ   28  2,688\n",
       "5    West Indies\\nWI   29  2,743\n",
       "6    Bangladesh\\nBAN   14    977\n",
       "7      Sri Lanka\\nSL   12    820\n",
       "8      Thailand\\nTHA   12    806\n",
       "9      Pakistan\\nPAK   27  1,678\n",
       "10      Ireland\\nIRE   16    605\n",
       "11  Netherlands\\nNED   10     90\n",
       "12     Zimbabwe\\nZIM   11      0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Send Get Request\n",
    "page = requests.get('https://www.icc-cricket.com/rankings/womens/player-rankings/odi/batting')\n",
    "\n",
    "# Create a BeautifulSoup object\n",
    "soup = BeautifulSoup(page.content)\n",
    "\n",
    "#Extracting the table header Batting in top 10\n",
    "table = soup.find('table', class_=\"table rankings-table\")\n",
    "title = [i.text for i in table.find_all('th')]\n",
    "\n",
    "#Extracting the tabledata Batting in top 10\n",
    "data_cells = []\n",
    "table_body = soup.find('tbody')\n",
    "table_body_rows = soup.find_all('tr')[1:11]\n",
    "\n",
    "for row in table_body_rows:\n",
    "    col = row.find_all(['td'])\n",
    "    col = [ele.text.strip() for ele in col]\n",
    "    data_cells.append(col)\n",
    "\n",
    "celldata = [[i.split('\\n')[0] for i in cell] for cell in data_cells]\n",
    "\n",
    "# Making DataFrame\n",
    "womens_Top_10_Batting = pd.DataFrame(data = data, columns = title)\n",
    "womens_Top_10_Batting.drop(['Pos', 'Career Best Rating'], axis=1, inplace=True)\n",
    "womens_Top_10_Batting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "739826f0",
   "metadata": {},
   "source": [
    "#### 3. Top 10 women’s ODI all-rounder along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "37d76a3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>Team</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chamari Athapaththu</td>\n",
       "      <td>SL</td>\n",
       "      <td>758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Beth Mooney</td>\n",
       "      <td>AUS</td>\n",
       "      <td>754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Laura Wolvaardt</td>\n",
       "      <td>SA</td>\n",
       "      <td>732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Natalie Sciver</td>\n",
       "      <td>ENG</td>\n",
       "      <td>731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Meg Lanning</td>\n",
       "      <td>AUS</td>\n",
       "      <td>717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Harmanpreet Kaur</td>\n",
       "      <td>IND</td>\n",
       "      <td>716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Smriti Mandhana</td>\n",
       "      <td>IND</td>\n",
       "      <td>714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Ellyse Perry</td>\n",
       "      <td>AUS</td>\n",
       "      <td>626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Stafanie Taylor</td>\n",
       "      <td>WI</td>\n",
       "      <td>618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Tammy Beaumont</td>\n",
       "      <td>ENG</td>\n",
       "      <td>595</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Player Team Rating\n",
       "0  Chamari Athapaththu   SL    758\n",
       "1          Beth Mooney  AUS    754\n",
       "2      Laura Wolvaardt   SA    732\n",
       "3       Natalie Sciver  ENG    731\n",
       "4          Meg Lanning  AUS    717\n",
       "5     Harmanpreet Kaur  IND    716\n",
       "6      Smriti Mandhana  IND    714\n",
       "7         Ellyse Perry  AUS    626\n",
       "8      Stafanie Taylor   WI    618\n",
       "9       Tammy Beaumont  ENG    595"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Send Get Request\n",
    "\n",
    "page = requests.get('https://www.icc-cricket.com/rankings/womens/player-rankings/odi/all-rounder')\n",
    "\n",
    "soup = BeautifulSoup(page.content)\n",
    "\n",
    "#Extracting the table header All-Rounder Rankings in top 10\n",
    "table = soup.find('table', class_=\"table rankings-table\")\n",
    "head = [i.text for i in table.find_all('th')]\n",
    "\n",
    "#Extracting the table data All-Rounder Rankings in top 10\n",
    "rows = []\n",
    "\n",
    "table_body = soup.find('tbody')\n",
    "table_body_rows = soup.find_all('tr')[1::11]\n",
    "\n",
    "for row in table_body_rows:\n",
    "    col = row.find_all(['td'])\n",
    "    col = [ele.text.strip() for ele in col]\n",
    "    data_cells.append(col)\n",
    "\n",
    "celldata = [[i.split('\\n')[0] for i in cell] for cell in data_cells]\n",
    "\n",
    "#taking Top 10 Womens batting Player\n",
    "data = celldata[:10]\n",
    "\n",
    "#Making Dataframe\n",
    "rounder = pd.DataFrame(data = data, columns=head)\n",
    "rounder.drop(['Pos','Career Best Rating'], axis=1, inplace=True)\n",
    "rounder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e8426bb",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f787ac1b",
   "metadata": {},
   "source": [
    "### **Question: 5** Write a python program to scrape mentioned news details from https://www.cnbc.com/world/?region=world and make data frame\n",
    "1. Headline\n",
    "2. Time\n",
    "3. News Link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ac08058",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Headline</th>\n",
       "      <th>Time</th>\n",
       "      <th>links</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Volkswagen will test self-driving cars in Aust...</td>\n",
       "      <td>43 Min Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/07/06/volkswagen-mob...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ford's U.S. sales jump 9.9% on big gains for i...</td>\n",
       "      <td>44 Min Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/07/06/fords-second-q...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Elon Musk praises China's 'very strong' A.I. c...</td>\n",
       "      <td>1 Hour Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/07/06/elon-musk-chin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Trump aide Walt Nauta set to be arraigned in c...</td>\n",
       "      <td>1 Hour Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/07/06/trump-aide-wal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jim Cramer's top 10 things to watch in the sto...</td>\n",
       "      <td>2 Hours Ago</td>\n",
       "      <td>/investingclub/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>How Delta is upgrading its fleet for better cu...</td>\n",
       "      <td>2 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/07/06/how-delta-is-u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Bitcoin touches 13-month high on optimism a Bl...</td>\n",
       "      <td>2 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/07/06/bitcoin-touche...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Private sector adds 497,000 jobs in June, more...</td>\n",
       "      <td>2 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/07/06/adp-jobs-repor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Amazon sellers say they were kicked off site a...</td>\n",
       "      <td>2 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/07/06/amazon-sellers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Stocks making the biggest moves premarket: Jet...</td>\n",
       "      <td>2 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/07/06/stocks-making-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Buy Keurig Dr Pepper as the stock prices in to...</td>\n",
       "      <td>2 Hours Ago</td>\n",
       "      <td>/pro/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>JPMorgan warns UK could see 'hard landing,' sa...</td>\n",
       "      <td>3 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/07/06/boe-could-hike...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>BofA upgrades Sweetgreen, says automation can ...</td>\n",
       "      <td>3 Hours Ago</td>\n",
       "      <td>/pro/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Qatar Airways reports record revenues, bolster...</td>\n",
       "      <td>3 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/07/06/qatar-airways-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Mortgage demand drops to lowest level in a mon...</td>\n",
       "      <td>3 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/07/06/mortgage-deman...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Citi says buy this aircraft maker with more th...</td>\n",
       "      <td>3 Hours Ago</td>\n",
       "      <td>/pro/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>5 things to know before the stock market opens...</td>\n",
       "      <td>3 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/07/06/5-things-to-kn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Wolfe Research says buy this mall operator tha...</td>\n",
       "      <td>4 Hours Ago</td>\n",
       "      <td>/pro/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>TotalEnergies CEO defends strategy despite cal...</td>\n",
       "      <td>4 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/07/06/totalenergies-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>This green hydrogen stock can rally more than ...</td>\n",
       "      <td>4 Hours Ago</td>\n",
       "      <td>/pro/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Janet Yellen arrives in Beijing on mission to ...</td>\n",
       "      <td>5 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/07/06/janet-yellen-a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>China says it told the U.S. and Europe about t...</td>\n",
       "      <td>6 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/07/06/china-says-it-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2-year Treasury yield hits 16-year high after ...</td>\n",
       "      <td>6 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/07/06/us-treasurys-i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>OPEC chief says the search is on for new membe...</td>\n",
       "      <td>7 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/07/06/opec-chief-say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>A $12 phone is opening doors for rural India t...</td>\n",
       "      <td>7 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/07/06/reliance-jio-b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>CNBC Daily Open: Brace yourself for higher rates</td>\n",
       "      <td>8 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/07/06/stock-markets-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Wagner leader Prigozhin in St. Petersburg, Bel...</td>\n",
       "      <td>8 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/07/06/ukraine-war-li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Chinese investors are not expecting much stimu...</td>\n",
       "      <td>8 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/07/06/local-investor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>European stocks down nearly 2% after strong U....</td>\n",
       "      <td>8 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/07/06/european-marke...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Bad news for nervous flyers: Turbulence is get...</td>\n",
       "      <td>9 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/07/06/bad-news-for-n...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Headline         Time  \\\n",
       "0   Volkswagen will test self-driving cars in Aust...   43 Min Ago   \n",
       "1   Ford's U.S. sales jump 9.9% on big gains for i...   44 Min Ago   \n",
       "2   Elon Musk praises China's 'very strong' A.I. c...   1 Hour Ago   \n",
       "3   Trump aide Walt Nauta set to be arraigned in c...   1 Hour Ago   \n",
       "4   Jim Cramer's top 10 things to watch in the sto...  2 Hours Ago   \n",
       "5   How Delta is upgrading its fleet for better cu...  2 Hours Ago   \n",
       "6   Bitcoin touches 13-month high on optimism a Bl...  2 Hours Ago   \n",
       "7   Private sector adds 497,000 jobs in June, more...  2 Hours Ago   \n",
       "8   Amazon sellers say they were kicked off site a...  2 Hours Ago   \n",
       "9   Stocks making the biggest moves premarket: Jet...  2 Hours Ago   \n",
       "10  Buy Keurig Dr Pepper as the stock prices in to...  2 Hours Ago   \n",
       "11  JPMorgan warns UK could see 'hard landing,' sa...  3 Hours Ago   \n",
       "12  BofA upgrades Sweetgreen, says automation can ...  3 Hours Ago   \n",
       "13  Qatar Airways reports record revenues, bolster...  3 Hours Ago   \n",
       "14  Mortgage demand drops to lowest level in a mon...  3 Hours Ago   \n",
       "15  Citi says buy this aircraft maker with more th...  3 Hours Ago   \n",
       "16  5 things to know before the stock market opens...  3 Hours Ago   \n",
       "17  Wolfe Research says buy this mall operator tha...  4 Hours Ago   \n",
       "18  TotalEnergies CEO defends strategy despite cal...  4 Hours Ago   \n",
       "19  This green hydrogen stock can rally more than ...  4 Hours Ago   \n",
       "20  Janet Yellen arrives in Beijing on mission to ...  5 Hours Ago   \n",
       "21  China says it told the U.S. and Europe about t...  6 Hours Ago   \n",
       "22  2-year Treasury yield hits 16-year high after ...  6 Hours Ago   \n",
       "23  OPEC chief says the search is on for new membe...  7 Hours Ago   \n",
       "24  A $12 phone is opening doors for rural India t...  7 Hours Ago   \n",
       "25   CNBC Daily Open: Brace yourself for higher rates  8 Hours Ago   \n",
       "26  Wagner leader Prigozhin in St. Petersburg, Bel...  8 Hours Ago   \n",
       "27  Chinese investors are not expecting much stimu...  8 Hours Ago   \n",
       "28  European stocks down nearly 2% after strong U....  8 Hours Ago   \n",
       "29  Bad news for nervous flyers: Turbulence is get...  9 Hours Ago   \n",
       "\n",
       "                                                links  \n",
       "0   https://www.cnbc.com/2023/07/06/volkswagen-mob...  \n",
       "1   https://www.cnbc.com/2023/07/06/fords-second-q...  \n",
       "2   https://www.cnbc.com/2023/07/06/elon-musk-chin...  \n",
       "3   https://www.cnbc.com/2023/07/06/trump-aide-wal...  \n",
       "4                                     /investingclub/  \n",
       "5   https://www.cnbc.com/2023/07/06/how-delta-is-u...  \n",
       "6   https://www.cnbc.com/2023/07/06/bitcoin-touche...  \n",
       "7   https://www.cnbc.com/2023/07/06/adp-jobs-repor...  \n",
       "8   https://www.cnbc.com/2023/07/06/amazon-sellers...  \n",
       "9   https://www.cnbc.com/2023/07/06/stocks-making-...  \n",
       "10                                              /pro/  \n",
       "11  https://www.cnbc.com/2023/07/06/boe-could-hike...  \n",
       "12                                              /pro/  \n",
       "13  https://www.cnbc.com/2023/07/06/qatar-airways-...  \n",
       "14  https://www.cnbc.com/2023/07/06/mortgage-deman...  \n",
       "15                                              /pro/  \n",
       "16  https://www.cnbc.com/2023/07/06/5-things-to-kn...  \n",
       "17                                              /pro/  \n",
       "18  https://www.cnbc.com/2023/07/06/totalenergies-...  \n",
       "19                                              /pro/  \n",
       "20  https://www.cnbc.com/2023/07/06/janet-yellen-a...  \n",
       "21  https://www.cnbc.com/2023/07/06/china-says-it-...  \n",
       "22  https://www.cnbc.com/2023/07/06/us-treasurys-i...  \n",
       "23  https://www.cnbc.com/2023/07/06/opec-chief-say...  \n",
       "24  https://www.cnbc.com/2023/07/06/reliance-jio-b...  \n",
       "25  https://www.cnbc.com/2023/07/06/stock-markets-...  \n",
       "26  https://www.cnbc.com/2023/07/06/ukraine-war-li...  \n",
       "27  https://www.cnbc.com/2023/07/06/local-investor...  \n",
       "28  https://www.cnbc.com/2023/07/06/european-marke...  \n",
       "29  https://www.cnbc.com/2023/07/06/bad-news-for-n...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get Request\n",
    "page = requests.get('https://www.cnbc.com/world/?region=world')\n",
    "\n",
    "#Page Content\n",
    "soup = BeautifulSoup(page.content)\n",
    "\n",
    "# Articles in the website\n",
    "articles = soup.find_all('div', class_=\"LatestNews-headlineWrapper\")\n",
    "\n",
    "# Extracting Headlines from the article\n",
    "Headlines = [i.find('a', class_=\"LatestNews-headline\").text for i in articles]\n",
    "\n",
    "# Extracting links of the headlines\n",
    "links = [i.find('a')['href'] for i in articles]\n",
    "\n",
    "#extracting time\n",
    "time = [i.find('time', class_=\"LatestNews-timestamp\").text for i in articles]\n",
    "\n",
    "#Making DataFrame\n",
    "News = pd.DataFrame({\"Headline\": Headlines, \"Time\":time, \"links\":links})\n",
    "News"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1169b03d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dce28aa",
   "metadata": {},
   "source": [
    "### **Question: 6** Write a python program to scrape the details of most downloaded articles from AI in last 90 days.https://www.journals.elsevier.com/artificial-intelligence/most-downloaded-articles Scrape below mentioned details and make data frame\n",
    "1. Paper Title\n",
    "2. Authors\n",
    "3. Published Date\n",
    "4.  Paper URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "029ede5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Paper Title</th>\n",
       "      <th>Author</th>\n",
       "      <th>Published Date</th>\n",
       "      <th>Paper URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Reward is enough</td>\n",
       "      <td>David Silver, Satinder Singh, Doina Precup, Ri...</td>\n",
       "      <td>October 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Explanation in artificial intelligence: Insigh...</td>\n",
       "      <td>Tim Miller</td>\n",
       "      <td>February 2019</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Creativity and artificial intelligence</td>\n",
       "      <td>Margaret A. Boden</td>\n",
       "      <td>August 1998</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Conflict-based search for optimal multi-agent ...</td>\n",
       "      <td>Guni Sharon, Roni Stern, Ariel Felner, Nathan ...</td>\n",
       "      <td>February 2015</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Knowledge graphs as tools for explainable mach...</td>\n",
       "      <td>Ilaria Tiddi, Stefan Schlobach</td>\n",
       "      <td>January 2022</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Law and logic: A review from an argumentation ...</td>\n",
       "      <td>Henry Prakken, Giovanni Sartor</td>\n",
       "      <td>October 2015</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Between MDPs and semi-MDPs: A framework for te...</td>\n",
       "      <td>Richard S. Sutton, Doina Precup, Satinder Singh</td>\n",
       "      <td>August 1999</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Explaining individual predictions when feature...</td>\n",
       "      <td>Kjersti Aas, Martin Jullum, Anders Løland</td>\n",
       "      <td>September 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Multiple object tracking: A literature review</td>\n",
       "      <td>Wenhan Luo, Junliang Xing and 4 more</td>\n",
       "      <td>April 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>A survey of inverse reinforcement learning: Ch...</td>\n",
       "      <td>Saurabh Arora, Prashant Doshi</td>\n",
       "      <td>August 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Evaluating XAI: A comparison of rule-based and...</td>\n",
       "      <td>Jasper van der Waa, Elisabeth Nieuwburg, Anita...</td>\n",
       "      <td>February 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Explainable AI tools for legal reasoning about...</td>\n",
       "      <td>Joe Collenette, Katie Atkinson, Trevor Bench-C...</td>\n",
       "      <td>April 2023</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Hard choices in artificial intelligence</td>\n",
       "      <td>Roel Dobbe, Thomas Krendl Gilbert, Yonatan Mintz</td>\n",
       "      <td>November 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Assessing the communication gap between AI mod...</td>\n",
       "      <td>Oskar Wysocki, Jessica Katharine Davies and 5 ...</td>\n",
       "      <td>March 2023</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Explaining black-box classifiers using post-ho...</td>\n",
       "      <td>Eoin M. Kenny, Courtney Ford, Molly Quinn, Mar...</td>\n",
       "      <td>May 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>The Hanabi challenge: A new frontier for AI re...</td>\n",
       "      <td>Nolan Bard, Jakob N. Foerster and 13 more</td>\n",
       "      <td>March 2020</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Wrappers for feature subset selection</td>\n",
       "      <td>Ron Kohavi, George H. John</td>\n",
       "      <td>December 1997</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Artificial cognition for social human–robot in...</td>\n",
       "      <td>Séverin Lemaignan, Mathieu Warnier and 3 more</td>\n",
       "      <td>June 2017</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>A review of possible effects of cognitive bias...</td>\n",
       "      <td>Tomáš Kliegr, Štěpán Bahník, Johannes Fürnkranz</td>\n",
       "      <td>June 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>The multifaceted impact of Ada Lovelace in the...</td>\n",
       "      <td>Luigia Carlucci Aiello</td>\n",
       "      <td>June 2016</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Robot ethics: Mapping the issues for a mechani...</td>\n",
       "      <td>Patrick Lin, Keith Abney, George Bekey</td>\n",
       "      <td>April 2011</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Reward (Mis)design for autonomous driving</td>\n",
       "      <td>W. Bradley Knox, Alessandro Allievi and 3 more</td>\n",
       "      <td>March 2023</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Planning and acting in partially observable st...</td>\n",
       "      <td>Leslie Pack Kaelbling, Michael L. Littman, Ant...</td>\n",
       "      <td>May 1998</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>What do we want from Explainable Artificial In...</td>\n",
       "      <td>Markus Langer, Daniel Oster and 6 more</td>\n",
       "      <td>July 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Paper Title  \\\n",
       "0                                    Reward is enough   \n",
       "1   Explanation in artificial intelligence: Insigh...   \n",
       "2              Creativity and artificial intelligence   \n",
       "3   Conflict-based search for optimal multi-agent ...   \n",
       "4   Knowledge graphs as tools for explainable mach...   \n",
       "5   Law and logic: A review from an argumentation ...   \n",
       "6   Between MDPs and semi-MDPs: A framework for te...   \n",
       "7   Explaining individual predictions when feature...   \n",
       "8       Multiple object tracking: A literature review   \n",
       "9   A survey of inverse reinforcement learning: Ch...   \n",
       "10  Evaluating XAI: A comparison of rule-based and...   \n",
       "11  Explainable AI tools for legal reasoning about...   \n",
       "12            Hard choices in artificial intelligence   \n",
       "13  Assessing the communication gap between AI mod...   \n",
       "14  Explaining black-box classifiers using post-ho...   \n",
       "15  The Hanabi challenge: A new frontier for AI re...   \n",
       "16              Wrappers for feature subset selection   \n",
       "17  Artificial cognition for social human–robot in...   \n",
       "18  A review of possible effects of cognitive bias...   \n",
       "19  The multifaceted impact of Ada Lovelace in the...   \n",
       "20  Robot ethics: Mapping the issues for a mechani...   \n",
       "21          Reward (Mis)design for autonomous driving   \n",
       "22  Planning and acting in partially observable st...   \n",
       "23  What do we want from Explainable Artificial In...   \n",
       "\n",
       "                                               Author  Published Date  \\\n",
       "0   David Silver, Satinder Singh, Doina Precup, Ri...    October 2021   \n",
       "1                                         Tim Miller    February 2019   \n",
       "2                                  Margaret A. Boden      August 1998   \n",
       "3   Guni Sharon, Roni Stern, Ariel Felner, Nathan ...   February 2015   \n",
       "4                     Ilaria Tiddi, Stefan Schlobach     January 2022   \n",
       "5                     Henry Prakken, Giovanni Sartor     October 2015   \n",
       "6    Richard S. Sutton, Doina Precup, Satinder Singh      August 1999   \n",
       "7          Kjersti Aas, Martin Jullum, Anders Løland   September 2021   \n",
       "8                Wenhan Luo, Junliang Xing and 4 more      April 2021   \n",
       "9                      Saurabh Arora, Prashant Doshi      August 2021   \n",
       "10  Jasper van der Waa, Elisabeth Nieuwburg, Anita...   February 2021   \n",
       "11  Joe Collenette, Katie Atkinson, Trevor Bench-C...      April 2023   \n",
       "12  Roel Dobbe, Thomas Krendl Gilbert, Yonatan Mintz    November 2021   \n",
       "13  Oskar Wysocki, Jessica Katharine Davies and 5 ...      March 2023   \n",
       "14  Eoin M. Kenny, Courtney Ford, Molly Quinn, Mar...        May 2021   \n",
       "15          Nolan Bard, Jakob N. Foerster and 13 more      March 2020   \n",
       "16                        Ron Kohavi, George H. John    December 1997   \n",
       "17      Séverin Lemaignan, Mathieu Warnier and 3 more       June 2017   \n",
       "18   Tomáš Kliegr, Štěpán Bahník, Johannes Fürnkranz        June 2021   \n",
       "19                            Luigia Carlucci Aiello        June 2016   \n",
       "20            Patrick Lin, Keith Abney, George Bekey       April 2011   \n",
       "21     W. Bradley Knox, Alessandro Allievi and 3 more      March 2023   \n",
       "22  Leslie Pack Kaelbling, Michael L. Littman, Ant...        May 1998   \n",
       "23             Markus Langer, Daniel Oster and 6 more       July 2021   \n",
       "\n",
       "                                            Paper URL  \n",
       "0   https://www.sciencedirect.com/science/article/...  \n",
       "1   https://www.sciencedirect.com/science/article/...  \n",
       "2   https://www.sciencedirect.com/science/article/...  \n",
       "3   https://www.sciencedirect.com/science/article/...  \n",
       "4   https://www.sciencedirect.com/science/article/...  \n",
       "5   https://www.sciencedirect.com/science/article/...  \n",
       "6   https://www.sciencedirect.com/science/article/...  \n",
       "7   https://www.sciencedirect.com/science/article/...  \n",
       "8   https://www.sciencedirect.com/science/article/...  \n",
       "9   https://www.sciencedirect.com/science/article/...  \n",
       "10  https://www.sciencedirect.com/science/article/...  \n",
       "11  https://www.sciencedirect.com/science/article/...  \n",
       "12  https://www.sciencedirect.com/science/article/...  \n",
       "13  https://www.sciencedirect.com/science/article/...  \n",
       "14  https://www.sciencedirect.com/science/article/...  \n",
       "15  https://www.sciencedirect.com/science/article/...  \n",
       "16  https://www.sciencedirect.com/science/article/...  \n",
       "17  https://www.sciencedirect.com/science/article/...  \n",
       "18  https://www.sciencedirect.com/science/article/...  \n",
       "19  https://www.sciencedirect.com/science/article/...  \n",
       "20  https://www.sciencedirect.com/science/article/...  \n",
       "21  https://www.sciencedirect.com/science/article/...  \n",
       "22  https://www.sciencedirect.com/science/article/...  \n",
       "23  https://www.sciencedirect.com/science/article/...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get Request\n",
    "url = requests.get('https://www.journals.elsevier.com/artificial-intelligence/most-downloaded-articles')\n",
    "\n",
    "# Page Content\n",
    "soup = BeautifulSoup(url.content)\n",
    "\n",
    "#Extracting Titles\n",
    "paper_tiles = [i.text for i in soup.find_all('a',class_=\"sc-5smygv-0 fIXTHm\")]\n",
    "\n",
    "#Extracting Author Name\n",
    "author = [i.text for i in soup.find_all('span', class_=\"sc-1w3fpd7-0 dnCnAO\")]\n",
    "author\n",
    "\n",
    "#extracting Published date\n",
    "date = [i.text for i in soup.find_all('span',class_=\"sc-1thf9ly-2 dvggWt\")]\n",
    "\n",
    "# Extracting All Paper links\n",
    "paper = [i.get('href') for i in soup.find_all('a', class_=\"sc-5smygv-0 fIXTHm\")]\n",
    "\n",
    "#Making DataFrame\n",
    "df = pd.DataFrame({'Paper Title':paper_tiles, 'Author':author, 'Published Date':date, 'Paper URL':paper})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decb8d52",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "575ee0ac",
   "metadata": {},
   "source": [
    "###  **Question: 7** Write a python program to scrape mentioned details from dineout.co.inand make data frame\n",
    "1. Restaurant name\n",
    "2. Cuisine\n",
    "3. Location\n",
    "4. Ratings\n",
    "5. Image URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7b1c5480",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Restaurant Names</th>\n",
       "      <th>Cuisine</th>\n",
       "      <th>Location</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Images</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Castle Barbeque</td>\n",
       "      <td>Chinese, North Indian</td>\n",
       "      <td>Connaught Place, Central Delhi</td>\n",
       "      <td>4</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jungle Jamboree</td>\n",
       "      <td>North Indian, Asian, Italian</td>\n",
       "      <td>3CS Mall,Lajpat Nagar - 3, South Delhi</td>\n",
       "      <td>3.9</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cafe Knosh</td>\n",
       "      <td>Italian, Continental</td>\n",
       "      <td>The Leela Ambience Convention Hotel,Shahdara, ...</td>\n",
       "      <td>4.3</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Castle's Barbeque</td>\n",
       "      <td>Chinese, North Indian</td>\n",
       "      <td>Pacific Mall,Tagore Garden, West Delhi</td>\n",
       "      <td>3.9</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Barbeque Company</td>\n",
       "      <td>North Indian, Chinese</td>\n",
       "      <td>Gardens Galleria,Sector 38A, Noida</td>\n",
       "      <td>3.9</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>India Grill</td>\n",
       "      <td>North Indian, Italian</td>\n",
       "      <td>Hilton Garden Inn,Saket, South Delhi</td>\n",
       "      <td>3.9</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Delhi Barbeque</td>\n",
       "      <td>North Indian</td>\n",
       "      <td>Taurus Sarovar Portico,Mahipalpur, South Delhi</td>\n",
       "      <td>3.7</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The Monarch - Bar Be Que Village</td>\n",
       "      <td>North Indian</td>\n",
       "      <td>Indirapuram Habitat Centre,Indirapuram, Ghaziabad</td>\n",
       "      <td>3.8</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Indian Grill Room</td>\n",
       "      <td>North Indian, Mughlai</td>\n",
       "      <td>Suncity Business Tower,Golf Course Road, Gurgaon</td>\n",
       "      <td>4.3</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Restaurant Names                        Cuisine  \\\n",
       "0                   Castle Barbeque          Chinese, North Indian   \n",
       "1                   Jungle Jamboree   North Indian, Asian, Italian   \n",
       "2                        Cafe Knosh           Italian, Continental   \n",
       "3                 Castle's Barbeque          Chinese, North Indian   \n",
       "4              The Barbeque Company          North Indian, Chinese   \n",
       "5                       India Grill          North Indian, Italian   \n",
       "6                    Delhi Barbeque                   North Indian   \n",
       "7  The Monarch - Bar Be Que Village                   North Indian   \n",
       "8                 Indian Grill Room          North Indian, Mughlai   \n",
       "\n",
       "                                            Location Rating  \\\n",
       "0                     Connaught Place, Central Delhi      4   \n",
       "1             3CS Mall,Lajpat Nagar - 3, South Delhi    3.9   \n",
       "2  The Leela Ambience Convention Hotel,Shahdara, ...    4.3   \n",
       "3             Pacific Mall,Tagore Garden, West Delhi    3.9   \n",
       "4                 Gardens Galleria,Sector 38A, Noida    3.9   \n",
       "5               Hilton Garden Inn,Saket, South Delhi    3.9   \n",
       "6     Taurus Sarovar Portico,Mahipalpur, South Delhi    3.7   \n",
       "7  Indirapuram Habitat Centre,Indirapuram, Ghaziabad    3.8   \n",
       "8   Suncity Business Tower,Golf Course Road, Gurgaon    4.3   \n",
       "\n",
       "                                              Images  \n",
       "0  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "1  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "2  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "3  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "4  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "5  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "6  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "7  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "8  https://im1.dineout.co.in/images/uploads/resta...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get Request\n",
    "page = requests.get('https://www.dineout.co.in/delhi-restaurants/buffet-special')\n",
    "\n",
    "# Page Content\n",
    "soup = BeautifulSoup(page.content)\n",
    "\n",
    "# 1. Scrapping Restaurant name\n",
    "names = [i.text for i in soup.find_all('a',class_=\"restnt-name ellipsis\")]\n",
    "\n",
    "# 2. Scrapping cuisine\n",
    "cuisine = [i.text.split('|')[1] for i in soup.find_all('span', class_=\"double-line-ellipsis\")]\n",
    "\n",
    "# 3. Scrapping Location\n",
    "location = [i.text for i in soup.find_all('div', class_=\"restnt-loc ellipsis\")]\n",
    "location\n",
    "\n",
    "# 4. Scrapping Ratings\n",
    "ratings = [i.text for i in soup.find_all('div', class_=\"restnt-rating rating-4\")]\n",
    "\n",
    "\n",
    "# 5. Scrapping Image Urls\n",
    "images = [i.get('data-src') for i in soup.find_all('img', class_=\"no-img\")]\n",
    "\n",
    "#Making DataFrame\n",
    "pd = pd.DataFrame({'Restaurant Names':names, 'Cuisine':cuisine, 'Location':location, 'Rating':ratings,'Images':images })\n",
    "pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "796a2b75",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
